{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on testing:\n",
    "1. SDR is missing as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"pip install --upgrade torchmetrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetConv10().to(device)\n",
    "denoiser = DenoisingLoader(model, load_path)\n",
    "model = denoiser.model\n",
    "print('Loaded Model')\n",
    "\n",
    "# Example input (batch_size=1, channels=2, height=1025, width=175)\n",
    "noisy_input = torch.randn(1, 9, 1025, 175)\n",
    "\n",
    "denoised_output = denoiser.denoise(noisy_input)\n",
    "print(denoised_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_TEST_NOISY = True\n",
    "load_dataframe = True\n",
    "max_file_size_gb = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
    "\n",
    "if IMPORT_TEST_NOISY:\n",
    "  if not os.path.exists(destination_path):\n",
    "    combine_h5_files_features(source_path, destination_path, max_file_size_gb=max_file_size_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioautoencoder.datasets.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(scaler_file):\n",
    "    print(\"Loading existing scalers...\")\n",
    "    scalers = load_scalers(scaler_file)\n",
    "else:\n",
    "    print(\"Training new scalers...\")\n",
    "    scalers = train_scalers_separation(dataset_path, sample_size=8000)\n",
    "    save_scalers(scalers, scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPORT_TEST_NOISY:\n",
    "    print(\"Loading existing scalers...\")\n",
    "    scalers = load_scalers(scaler_file)\n",
    "    test_loader = ChannelDatasetLoader(\n",
    "          dataset_path=save_path,\n",
    "          scalers=scalers,\n",
    "          output_time_length=175,\n",
    "          channels=1,\n",
    "          snr_db=SNRdB,\n",
    "          subset=True,\n",
    "          batch_size=4\n",
    "      )\n",
    "\n",
    "    print(f\"Training set size: {len(test_loader.train_dataset)}\")\n",
    "    print(f\"Validation set size: {len(test_loader.val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioautoencoder.testing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_dataframe:\n",
    "  df_subset = pd.read_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_dataframe:\n",
    "  criterion = nn.L1Loss()\n",
    "  loss, df_eval = test_model(model, test_loader.train_loader, criterion, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_dataframe:\n",
    "  # Assuming `df` is your original dataframe\n",
    "  #df_eval[\"Improvement\"] = df_eval[\"l1_outvstar\"] df_eval[\"l1_invstar\"]  # Higher SDR is better\n",
    "  subset_columns = [\"instance\", \"l1_invstar\", \"l1_outvstar\", \"l1_invstar_4k\", \"l1_outvstar_4k\", \"l1_invstar_full\", \"l1_outvstar_full\",  \"filename\", \"snr_db\"] #\"Improvement\"]\n",
    "  df_subset = df_eval#[subset_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_dataframe:\n",
    "  # Create a function to map filename to a class\n",
    "  def get_class_from_filename(filename, classes):\n",
    "      for keyword in classes:\n",
    "          if keyword in filename:\n",
    "              return keyword\n",
    "      return 'Unknown'  # Default if no match found\n",
    "\n",
    "  df_subset[['filename_audio', 'filename_noise']] = pd.DataFrame(df_subset['filename'].tolist(), index=df_subset.index)\n",
    "  df_subset['filename_audio'] = df_subset['filename_audio'].apply(lambda x: x.decode('utf-8'))\n",
    "  df_subset['filename_noise'] = df_subset['filename_noise'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "  classes = ['mixture', 'vocals', 'drums', 'guitar', 'bass', 'piano', 'electric_guitar', 'acoustic_guitar', 'synthesizer', 'strings', 'brass']\n",
    "  df_subset['audio_class'] = df_subset['filename_audio'].apply(lambda x: get_class_from_filename(x, classes))\n",
    "\n",
    "  classes = ['0707', 'Rain', 'Crowd', 'Water', 'Ice']\n",
    "  df_subset['noise_class'] = df_subset['filename_noise'].apply(lambda x: get_class_from_filename(x, classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[\"Improvement_L1\"] = df_subset[\"l1_invstar\"] - df_subset[\"l1_outvstar\"]  # Lower L1 loss is better\n",
    "df_subset[\"Improvement_L1_4k\"] = df_subset[\"l1_invstar_4k\"] - df_subset[\"l1_outvstar_4k\"]  # Lower L1 loss is better\n",
    "df_subset[\"Improvement_L1_full\"] = df_subset[\"l1_invstar_full\"] - df_subset[\"l1_outvstar_full\"]  # Lower L1 loss is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_spectrogram(spectrogram, threshold):\n",
    "    \"\"\"\n",
    "    Zeroes out all values in the spectrogram that are below the given threshold.\n",
    "\n",
    "    Args:\n",
    "        spectrogram (np.ndarray): Input 2D array.\n",
    "        threshold (float): The threshold value.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The processed spectrogram with values below threshold set to zero.\n",
    "    \"\"\"\n",
    "    spectrogram = np.where(spectrogram >= threshold, spectrogram, 0)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 44100  # 44.1 kHz audio\n",
    "n_fft = 2048  # Adjust this for better resolution\n",
    "freqs = np.linspace(0, sampling_rate / 2, n_fft // 2 + 1)  # STFT frequency bins\n",
    "\n",
    "# Find indices corresponding to 0â€“4000 Hz\n",
    "min_freq, max_freq = 0, 4000\n",
    "freq_indices = np.where((freqs >= min_freq) & (freqs <= max_freq))[0]\n",
    "\n",
    "# in spectrogram\n",
    "index = 40\n",
    "\n",
    "snr_db = np.array(df_subset.loc[index, \"snr_db\"])\n",
    "print(snr_db)\n",
    "\n",
    "# lets evaluate this from a l1 loss perspective\n",
    "# reconstruct spectrogram\n",
    "out_spectrogram = np.array(df_subset.loc[index, \"out_track\"][0])\n",
    "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_hf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][1]), df_subset.loc[index, \"metadata\"][\"hf_shape\"])\n",
    "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_mf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][2]), df_subset.loc[index, \"metadata\"][\"mf_shape\"])\n",
    "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_lf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][3]), df_subset.loc[index, \"metadata\"][\"lf_shape\"])\n",
    "out_spec_copy = out_spectrogram\n",
    "\n",
    "out_spectrogram = threshold_spectrogram(out_spectrogram, np.mean(out_spectrogram)*0.75)\n",
    "\n",
    "# out, with no join\n",
    "out_track = np.array(df_subset.loc[index, \"out_track\"])[0]\n",
    "\n",
    "# out spectrogram\n",
    "in_spectrogram = df_subset.loc[index, \"in_track\"][0]\n",
    "\n",
    "# target\n",
    "tar_track = np.array(df_subset.loc[index, \"tar_track\"])[0]\n",
    "\n",
    "# inverse normalisation to 0 - 1\n",
    "out_spectrogram = (out_spectrogram - 0.5) * 3\n",
    "out_track = (out_track - 0.5) * 3\n",
    "in_spectrogram = (in_spectrogram - 0.5) * 3\n",
    "tar_track = (tar_track - 0.5) * 3\n",
    "\n",
    "# Inverse standardisation\n",
    "input_temp = tar_track\n",
    "in_spectrogram = scalers[\"input_features_spectrogram\"].inverse_transform(in_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
    "\n",
    "out_spectrogram = scalers[\"target_features_spectrogram\"].inverse_transform(out_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
    "out_track = scalers[\"target_features_spectrogram\"].inverse_transform(out_track.reshape(1, -1)).reshape(input_temp.shape)\n",
    "\n",
    "tar_track = scalers[\"target_features_spectrogram\"].inverse_transform(tar_track.reshape(1, -1)).reshape(input_temp.shape)\n",
    "\n",
    "# plot things\n",
    "# Plot spectrograms\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 15))\n",
    "\n",
    "axes[0].imshow(in_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
    "axes[0].set_title(\"Noisy Input (Log Scale)\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].set_ylim((1, 1000))\n",
    "\n",
    "axes[1].imshow(out_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
    "axes[1].set_title(\"Denoised Output (Log Scale) - reconstructed\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_ylim((1, 1000))\n",
    "\n",
    "axes[2].imshow(out_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
    "axes[2].set_title(\"Denoised Output (Log Scale)\")\n",
    "axes[2].set_yscale(\"log\")\n",
    "axes[2].set_ylim((1, 1000))\n",
    "\n",
    "axes[3].imshow(tar_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
    "axes[3].set_title(\"Clean Target (Log Scale)\")\n",
    "axes[3].set_yscale(\"log\")\n",
    "axes[3].set_ylim((1, 1000))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magphase_to_waveform(magnitude, phase, audio_length=44100):\n",
    "    \"\"\"\n",
    "    Converts a spectrogram image back into an audio waveform.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.array): Spectrogram image (3 channels).\n",
    "        sr (int): Sampling rate.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Reconstructed audio waveform.\n",
    "    \"\"\"\n",
    "    stft = magnitude * np.exp(1j * phase)\n",
    "    return librosa.istft(stft, length=audio_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "from google.colab import files\n",
    "import librosa\n",
    "\n",
    "# output waveform\n",
    "phase = df_subset.loc[index, \"metadata\"][\"phase\"]\n",
    "#phase = scalers[\"input_features_phase\"].inverse_transform(phase.reshape(1, -1)).reshape(input_temp.shape)\n",
    "print(np.max(phase))\n",
    "print(np.min(phase))\n",
    "\n",
    "# reverse log scale\n",
    "out_spectrogram = librosa.db_to_amplitude(out_spectrogram)\n",
    "signal = magphase_to_waveform(out_spectrogram, phase, 44100 * 2)\n",
    "\n",
    "# Save as WAV file\n",
    "output_filename = f\"denoised_audio_{index}:{snr_db}.wav\"\n",
    "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
    "\n",
    "# Download the file\n",
    "files.download(output_filename)\n",
    "\n",
    "tar_track = librosa.db_to_amplitude(tar_track)\n",
    "signal = magphase_to_waveform(tar_track, phase, 44100 * 2)\n",
    "\n",
    "# Save as WAV file\n",
    "output_filename = f\"audio_{index}:{snr_db}.wav\"\n",
    "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
    "\n",
    "# Download the file\n",
    "files.download(output_filename)\n",
    "\n",
    "in_spectrogram = librosa.db_to_amplitude(in_spectrogram)\n",
    "signal = magphase_to_waveform(in_spectrogram, phase, 44100 * 2)\n",
    "\n",
    "# Save as WAV file\n",
    "output_filename = f\"noisy_audio_{index}:{snr_db}.wav\"\n",
    "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
    "\n",
    "# Download the file\n",
    "files.download(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set minimal theme\n",
    "sns.set_theme(style=\"white\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df_eval = df_subset\n",
    "\n",
    "# Round SNR values to the nearest 0.5 to reduce noise\n",
    "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
    "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
    "\n",
    "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
    "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
    "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
    "\n",
    "# Line plot colored by 'audio_class'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Mean Improvement (SDR)\")\n",
    "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
    "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Line plot colored by 'noise_class'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Mean Improvement (SDR)\")\n",
    "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
    "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df_eval = df_subset\n",
    "\n",
    "# Round SNR values to the nearest 0.5 to reduce noise\n",
    "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
    "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
    "\n",
    "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
    "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
    "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
    "\n",
    "# Line plot colored by 'audio_class'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Mean Improvement (SDR)\")\n",
    "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
    "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Line plot colored by 'noise_class'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Mean Improvement (SDR)\")\n",
    "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
    "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = df_subset\n",
    "\n",
    "# Create a grouped boxplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(x=\"noise_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df)\n",
    "\n",
    "# Customize plot\n",
    "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig(output_path + f\"boxplot_all_L1.png\")\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter for 'crowd' noise class\n",
    "df_crowd = df_subset[df_subset[\"noise_class\"] == \"Crowd\"].copy()\n",
    "\n",
    "# Create a grouped boxplot\n",
    "plt.figure(figsize=(7, 5))\n",
    "ax = sns.boxplot(x=\"audio_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df_crowd)\n",
    "\n",
    "# Customize plot\n",
    "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
    "plt.xticks()\n",
    "#plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig(output_path + f\"boxplot_crowd_L1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the dataframe loaded in `df`\n",
    "# df = pd.read_csv('your_data.csv')  # Uncomment if loading from CSV\n",
    "df = df_subset\n",
    "\n",
    "# You can also add visualization here if you want to dive deeper\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a more interpretable colormap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df[['l1_invstar', 'l1_outvstar', 'snr_db', 'Improvement_L1']].corr(),\n",
    "            annot=True, cmap='mako', fmt=\".2f\", vmin=-1, vmax=1, center=0)\n",
    "\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save subset dataframe\n",
    "df_subset.to_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete large variables\n",
    "del df_subset, df_eval, df\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
