{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MLErdk55dYT"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uW1R-NqaTB",
        "outputId": "e791cfb1-eb13-4854-af82-36b31e1381ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ohND2-qaTC",
        "outputId": "3df8d85e-9da0-4c21-8510-eb0e9e6cbe8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout bandchannels\")\n",
        "    os.system(\"git pull origin bandchannels\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin bandchannels\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7TDd5eSmqaTC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjJuGbbf5dYU"
      },
      "source": [
        "Notes on testing:\n",
        "1. SDR is missing as a metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfisrfe5dYV"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.models._utils import IntermediateLayerGetter"
      ],
      "metadata": {
        "id": "oK-oTZXM7DR0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.models.UNetConv10mask import UNetConv10\n",
        "from audioautoencoder.training import DenoisingLoader"
      ],
      "metadata": {
        "id": "Sekt_USu7LW-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'UNetConv10_mask'\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdB = SNRdB_load\n",
        "load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "\n",
        "\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ],
      "metadata": {
        "id": "YBvUL2h17hku"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8fMr_OK5dYV",
        "outputId": "2272146c-0925-41f9-a8a9-eef523e3392b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from /content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_UNetConv10_mask_-10-10/Autoencodermodel_earlystopping.pth\n",
            "Loaded Model\n",
            "torch.Size([1, 4, 1025, 175])\n"
          ]
        }
      ],
      "source": [
        "# Add the custom class to the safe globals list\n",
        "torch.serialization.add_safe_globals([UNetConv10])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetConv10().to(device)\n",
        "\n",
        "# Now load your checkpoint normally\n",
        "denoiser = DenoisingLoader(model, load_path)\n",
        "model = denoiser.model\n",
        "print('Loaded Model')\n",
        "\n",
        "# Example input (batch_size=1, channels=2, height=1025, width=175)\n",
        "noisy_input = torch.randn(1, 9, 1025, 175)\n",
        "\n",
        "denoised_output = denoiser.denoise(noisy_input)\n",
        "print(denoised_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JHMoC4jb5dYW"
      },
      "outputs": [],
      "source": [
        "IMPORT_TEST_NOISY = True\n",
        "load_dataframe = True\n",
        "max_file_size_gb = 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.datasets.utils import *\n",
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.data_management import *\n",
        "from audioautoencoder.generate_dataset import *"
      ],
      "metadata": {
        "id": "NaguRh9whjqk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_diffusion = False\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "#load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = ['sep_features', 'all-noise_features', 'all-noise_features_2'][2] # sep\n",
        "\n",
        "scaler_file = load_path + \"scalers.pkl\"  # Static filename since it's unique per run\n",
        "os.makedirs(os.path.dirname(scaler_file), exist_ok=True)\n",
        "source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "source_path = source_folder + \"test/\""
      ],
      "metadata": {
        "id": "hpzrft8bjZ7x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Z6zhuo5dYW",
        "outputId": "7f71b817-2128-44f7-d214-935cf607ad98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_060808.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_082714.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_093144.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_061438.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_100803.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_110128.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_113918.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_095058.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_084320.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_060904.h5']\n",
            "Created new file: /content/SNRdB_-10-10/test/combined_000.h5\n",
            "Progress: 1.14 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_082714.h5\n",
            "Progress: 2.08 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_093144.h5\n",
            "Attempt 1 failed: [Errno 107] Transport endpoint is not connected. Retrying in 5 seconds.\n",
            "Progress: 3.22 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_100803.h5\n",
            "Progress: 4.17 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_110128.h5\n",
            "Progress: 5.3 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_095058.h5\n",
            "Finished combining files into 1 output files in /content/SNRdB_-10-10/test/\n"
          ]
        }
      ],
      "source": [
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if IMPORT_TEST_NOISY:\n",
        "  if not os.path.exists(destination_path):\n",
        "    combine_h5_files_features(source_path, destination_path, max_file_size_gb=max_file_size_gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ol6z8f0O5dYW"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.datasets.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/combined_000.h5\""
      ],
      "metadata": {
        "id": "tFpOxFIimnc0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "guDB9wtk5dYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5fe2f5-6a1b-4e80-b39d-82a0f293d6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing scalers...\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(scaler_file):\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "else:\n",
        "    print(\"Training new scalers...\")\n",
        "    scalers = train_scalers_separation(dataset_path, sample_size=8000)\n",
        "    save_scalers(scalers, scaler_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-bKvGXxi5dYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927a8c5a-8165-46f3-b530-f326d135e7ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing scalers...\n",
            "Dataset size: 1728\n",
            "Training set size: 483\n",
            "Validation set size: 121\n",
            "Training set size: 483\n",
            "Validation set size: 121\n"
          ]
        }
      ],
      "source": [
        "if IMPORT_TEST_NOISY:\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "    test_loader = ChannelDatasetLoader(\n",
        "          dataset_path=dataset_path,\n",
        "          scalers=scalers,\n",
        "          output_time_length=175,\n",
        "          channels=1,\n",
        "          snr_db=SNRdB,\n",
        "          subset=True,\n",
        "          batch_size=4\n",
        "      )\n",
        "\n",
        "    print(f\"Training set size: {len(test_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(test_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"pip install --upgrade torchmetrics\")"
      ],
      "metadata": {
        "id": "FELMtw5c06DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BsxwPLMc5dYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "b0f775c8-2cfe-46db-d2e4-4c82bc559b07"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchmetrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f5e3a382aad4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maudioautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSignalDistortionRatio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from audioautoencoder.testing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwNlkhm35dYW"
      },
      "outputs": [],
      "source": [
        "if load_dataframe:\n",
        "  df_subset = pd.read_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulf6mbLC5dYX"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeAt79Ep5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  criterion = nn.L1Loss()\n",
        "  loss, df_eval = test_model(model, test_loader.train_loader, criterion, scalers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5upsUwE65dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Assuming `df` is your original dataframe\n",
        "  #df_eval[\"Improvement\"] = df_eval[\"l1_outvstar\"] df_eval[\"l1_invstar\"]  # Higher SDR is better\n",
        "  subset_columns = [\"instance\", \"l1_invstar\", \"l1_outvstar\", \"l1_invstar_4k\", \"l1_outvstar_4k\", \"l1_invstar_full\", \"l1_outvstar_full\",  \"filename\", \"snr_db\"] #\"Improvement\"]\n",
        "  df_subset = df_eval#[subset_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_u803Xb5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Create a function to map filename to a class\n",
        "  def get_class_from_filename(filename, classes):\n",
        "      for keyword in classes:\n",
        "          if keyword in filename:\n",
        "              return keyword\n",
        "      return 'Unknown'  # Default if no match found\n",
        "\n",
        "  df_subset[['filename_audio', 'filename_noise']] = pd.DataFrame(df_subset['filename'].tolist(), index=df_subset.index)\n",
        "  df_subset['filename_audio'] = df_subset['filename_audio'].apply(lambda x: x.decode('utf-8'))\n",
        "  df_subset['filename_noise'] = df_subset['filename_noise'].apply(lambda x: x.decode('utf-8'))\n",
        "\n",
        "  classes = ['mixture', 'vocals', 'drums', 'guitar', 'bass', 'piano', 'electric_guitar', 'acoustic_guitar', 'synthesizer', 'strings', 'brass']\n",
        "  df_subset['audio_class'] = df_subset['filename_audio'].apply(lambda x: get_class_from_filename(x, classes))\n",
        "\n",
        "  classes = ['0707', 'Rain', 'Crowd', 'Water', 'Ice']\n",
        "  df_subset['noise_class'] = df_subset['filename_noise'].apply(lambda x: get_class_from_filename(x, classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0soXqrD5dYX"
      },
      "outputs": [],
      "source": [
        "df_subset[\"Improvement_L1\"] = df_subset[\"l1_invstar\"] - df_subset[\"l1_outvstar\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_4k\"] = df_subset[\"l1_invstar_4k\"] - df_subset[\"l1_outvstar_4k\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_full\"] = df_subset[\"l1_invstar_full\"] - df_subset[\"l1_outvstar_full\"]  # Lower L1 loss is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDQGuIQt5dYX"
      },
      "outputs": [],
      "source": [
        "def threshold_spectrogram(spectrogram, threshold):\n",
        "    \"\"\"\n",
        "    Zeroes out all values in the spectrogram that are below the given threshold.\n",
        "\n",
        "    Args:\n",
        "        spectrogram (np.ndarray): Input 2D array.\n",
        "        threshold (float): The threshold value.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The processed spectrogram with values below threshold set to zero.\n",
        "    \"\"\"\n",
        "    spectrogram = np.where(spectrogram >= threshold, spectrogram, 0)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbUP9Kqz5dYX"
      },
      "source": [
        "## View Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r24uLUeL5dYX"
      },
      "outputs": [],
      "source": [
        "sampling_rate = 44100  # 44.1 kHz audio\n",
        "n_fft = 2048  # Adjust this for better resolution\n",
        "freqs = np.linspace(0, sampling_rate / 2, n_fft // 2 + 1)  # STFT frequency bins\n",
        "\n",
        "# Find indices corresponding to 0â€“4000 Hz\n",
        "min_freq, max_freq = 0, 4000\n",
        "freq_indices = np.where((freqs >= min_freq) & (freqs <= max_freq))[0]\n",
        "\n",
        "# in spectrogram\n",
        "index = 40\n",
        "\n",
        "snr_db = np.array(df_subset.loc[index, \"snr_db\"])\n",
        "print(snr_db)\n",
        "\n",
        "# lets evaluate this from a l1 loss perspective\n",
        "# reconstruct spectrogram\n",
        "out_spectrogram = np.array(df_subset.loc[index, \"out_track\"][0])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_hf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][1]), df_subset.loc[index, \"metadata\"][\"hf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_mf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][2]), df_subset.loc[index, \"metadata\"][\"mf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_lf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][3]), df_subset.loc[index, \"metadata\"][\"lf_shape\"])\n",
        "out_spec_copy = out_spectrogram\n",
        "\n",
        "out_spectrogram = threshold_spectrogram(out_spectrogram, np.mean(out_spectrogram)*0.75)\n",
        "\n",
        "# out, with no join\n",
        "out_track = np.array(df_subset.loc[index, \"out_track\"])[0]\n",
        "\n",
        "# out spectrogram\n",
        "in_spectrogram = df_subset.loc[index, \"in_track\"][0]\n",
        "\n",
        "# target\n",
        "tar_track = np.array(df_subset.loc[index, \"tar_track\"])[0]\n",
        "\n",
        "# inverse normalisation to 0 - 1\n",
        "out_spectrogram = (out_spectrogram - 0.5) * 3\n",
        "out_track = (out_track - 0.5) * 3\n",
        "in_spectrogram = (in_spectrogram - 0.5) * 3\n",
        "tar_track = (tar_track - 0.5) * 3\n",
        "\n",
        "# Inverse standardisation\n",
        "input_temp = tar_track\n",
        "in_spectrogram = scalers[\"input_features_spectrogram\"].inverse_transform(in_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "out_spectrogram = scalers[\"target_features_spectrogram\"].inverse_transform(out_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "out_track = scalers[\"target_features_spectrogram\"].inverse_transform(out_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "tar_track = scalers[\"target_features_spectrogram\"].inverse_transform(tar_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "# plot things\n",
        "# Plot spectrograms\n",
        "fig, axes = plt.subplots(4, 1, figsize=(15, 15))\n",
        "\n",
        "axes[0].imshow(in_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[0].set_title(\"Noisy Input (Log Scale)\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].set_ylim((1, 1000))\n",
        "\n",
        "axes[1].imshow(out_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[1].set_title(\"Denoised Output (Log Scale) - reconstructed\")\n",
        "axes[1].set_yscale(\"log\")\n",
        "axes[1].set_ylim((1, 1000))\n",
        "\n",
        "axes[2].imshow(out_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[2].set_title(\"Denoised Output (Log Scale)\")\n",
        "axes[2].set_yscale(\"log\")\n",
        "axes[2].set_ylim((1, 1000))\n",
        "\n",
        "axes[3].imshow(tar_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[3].set_title(\"Clean Target (Log Scale)\")\n",
        "axes[3].set_yscale(\"log\")\n",
        "axes[3].set_ylim((1, 1000))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DsyfJNd5dYY"
      },
      "outputs": [],
      "source": [
        "def magphase_to_waveform(magnitude, phase, audio_length=44100):\n",
        "    \"\"\"\n",
        "    Converts a spectrogram image back into an audio waveform.\n",
        "\n",
        "    Parameters:\n",
        "        image (np.array): Spectrogram image (3 channels).\n",
        "        sr (int): Sampling rate.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Reconstructed audio waveform.\n",
        "    \"\"\"\n",
        "    stft = magnitude * np.exp(1j * phase)\n",
        "    return librosa.istft(stft, length=audio_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SloKTdbC5dYY"
      },
      "outputs": [],
      "source": [
        "import scipy.io.wavfile\n",
        "from google.colab import files\n",
        "import librosa\n",
        "\n",
        "# output waveform\n",
        "phase = df_subset.loc[index, \"metadata\"][\"phase\"]\n",
        "#phase = scalers[\"input_features_phase\"].inverse_transform(phase.reshape(1, -1)).reshape(input_temp.shape)\n",
        "print(np.max(phase))\n",
        "print(np.min(phase))\n",
        "\n",
        "# reverse log scale\n",
        "out_spectrogram = librosa.db_to_amplitude(out_spectrogram)\n",
        "signal = magphase_to_waveform(out_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"denoised_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "tar_track = librosa.db_to_amplitude(tar_track)\n",
        "signal = magphase_to_waveform(tar_track, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "in_spectrogram = librosa.db_to_amplitude(in_spectrogram)\n",
        "signal = magphase_to_waveform(in_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"noisy_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLO0zc_M5dYY"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0T5zh3S5dYY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set minimal theme\n",
        "sns.set_theme(style=\"white\", font_scale=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NfI_d_s5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "df_eval = df_subset\n",
        "\n",
        "# Round SNR values to the nearest 0.5 to reduce noise\n",
        "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
        "\n",
        "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
        "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
        "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
        "\n",
        "# Line plot colored by 'audio_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Line plot colored by 'noise_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqUfxeGB5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "df_eval = df_subset\n",
        "\n",
        "# Round SNR values to the nearest 0.5 to reduce noise\n",
        "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
        "\n",
        "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
        "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
        "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
        "\n",
        "# Line plot colored by 'audio_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Line plot colored by 'noise_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Iy5VG75dYY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = df_subset\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.boxplot(x=\"noise_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df)\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.ylim(-0.5, 0.5)\n",
        "plt.savefig(output_path + f\"boxplot_all_L1.png\")\n",
        "plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter for 'crowd' noise class\n",
        "df_crowd = df_subset[df_subset[\"noise_class\"] == \"Crowd\"].copy()\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sns.boxplot(x=\"audio_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df_crowd)\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks()\n",
        "#plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.ylim(-0.5, 0.5)\n",
        "plt.savefig(output_path + f\"boxplot_crowd_L1.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWIZ9QsG5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you already have the dataframe loaded in `df`\n",
        "# df = pd.read_csv('your_data.csv')  # Uncomment if loading from CSV\n",
        "df = df_subset\n",
        "\n",
        "# You can also add visualization here if you want to dive deeper\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a more interpretable colormap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['l1_invstar', 'l1_outvstar', 'snr_db', 'Improvement_L1']].corr(),\n",
        "            annot=True, cmap='mako', fmt=\".2f\", vmin=-1, vmax=1, center=0)\n",
        "\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o19dHk1o5dYZ"
      },
      "outputs": [],
      "source": [
        "# Save subset dataframe\n",
        "df_subset.to_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGHis62M5dYZ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "# Delete large variables\n",
        "del df_subset, df_eval, df\n",
        "\n",
        "# Force garbage collection\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvagagkU5dYZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnesqFwi5dYZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}