{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MLErdk55dYT"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "1. Output metrics need to be given in SDR too\n",
        "2. SNR's below 0 have high noise levels instead of low music levels - signal levels should be more randomised throughout the whole traning set. I'll to this by normalising the waveform after adding the noise, and then randomising the level to between 0 and -5 dB - this will allow me to double the training data from MUSDB18 by augmenting with different levels and noise masking.\n",
        "3. use just MUSDB18 so I can present this as research.   \n",
        "4. Given that I'm using the ESC50 set, i should be able to find what noise is what so I can label them when evaluating"
      ],
      "metadata": {
        "id": "EpURFH8OOrW7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uW1R-NqaTB",
        "outputId": "fed73e1b-e648-4ce7-839d-b854b5afd328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ohND2-qaTC",
        "outputId": "6eaf0df1-6f2d-41db-f5e8-20cbce5ea86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout dataset-generation-fix\")\n",
        "    os.system(\"git pull origin dataset-generation-fix\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin dataset-generation-fix\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7TDd5eSmqaTC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjJuGbbf5dYU"
      },
      "source": [
        "Notes on testing:\n",
        "1. SDR is missing as a metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfisrfe5dYV"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.models.UNetConv4 import *\n",
        "from audioautoencoder.training import DenoisingLoader"
      ],
      "metadata": {
        "id": "Sekt_USu7LW-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "aMk5EPzxBc1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'UNetConv4'\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdB = SNRdB_load\n",
        "load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "\n",
        "\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ],
      "metadata": {
        "id": "YBvUL2h17hku"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8fMr_OK5dYV",
        "outputId": "8a334aa1-2ebd-40c0-c0d3-750e692ce434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from /content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_UNetConv4_-10-10/Autoencodermodel_earlystopping.pth\n",
            "Loaded Model\n",
            "torch.Size([2, 4, 256, 175])\n"
          ]
        }
      ],
      "source": [
        "# Add the custom class to the safe globals list\n",
        "torch.serialization.add_safe_globals([UNetConv4])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetConv4(in_channels=4, out_channels=4).to(device)\n",
        "\n",
        "# Now load your checkpoint normally\n",
        "denoiser = DenoisingLoader(model, load_path)\n",
        "model = denoiser.model\n",
        "print('Loaded Model')\n",
        "\n",
        "# Example input (batch_size=1, channels=2, height=1025, width=175)\n",
        "noisy_input = torch.randn(2, 4, 1025 // 4, 175)\n",
        "\n",
        "denoised_output = denoiser.denoise(noisy_input)\n",
        "print(denoised_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JHMoC4jb5dYW"
      },
      "outputs": [],
      "source": [
        "IMPORT_TEST_NOISY = True\n",
        "load_dataframe = False\n",
        "max_file_size_gb = 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.datasets.utils import *\n",
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.data_management import *\n",
        "from audioautoencoder.generate_dataset import *"
      ],
      "metadata": {
        "id": "NaguRh9whjqk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_diffusion = False\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "#load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = ['sep_features', 'all-noise_features', 'all-noise_features_2'][2] # sep\n",
        "\n",
        "output_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/'\n",
        "scaler_file = output_path + \"scalers.pkl\"  # Static filename since it's unique per run\n",
        "os.makedirs(os.path.dirname(scaler_file), exist_ok=True)\n",
        "source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "source_path = source_folder + \"test/\""
      ],
      "metadata": {
        "id": "hpzrft8bjZ7x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "O9Z6zhuo5dYW",
        "outputId": "a0ddb654-04d2-4beb-bbc8-2aae3f116420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d19256b3195c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIMPORT_TEST_NOISY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcombine_h5_files_spectrograms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_file_size_gb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_file_size_gb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/generate_dataset.py\u001b[0m in \u001b[0;36mcombine_h5_files_spectrograms\u001b[0;34m(h5_folder_path, output_folder_path, max_file_size_gb, chunk_size, dst)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     h5_files = sorted(\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_folder_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     )\n\u001b[1;32m    560\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/'"
          ]
        }
      ],
      "source": [
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "if IMPORT_TEST_NOISY:\n",
        "  if not os.path.exists(destination_path):\n",
        "    combine_h5_files_spectrograms(source_path, destination_path, max_file_size_gb=max_file_size_gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol6z8f0O5dYW"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.datasets.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/combined_000.h5\""
      ],
      "metadata": {
        "id": "tFpOxFIimnc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guDB9wtk5dYW"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(scaler_file):\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "else:\n",
        "    print(\"Training new scalers...\")\n",
        "    scalers = train_scalers_separation(dataset_path, sample_size=8000)\n",
        "    save_scalers(scalers, scaler_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bKvGXxi5dYW"
      },
      "outputs": [],
      "source": [
        "if IMPORT_TEST_NOISY:\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "    test_loader = ChannelDatasetLoader(\n",
        "          dataset_path=dataset_path,\n",
        "          scalers=scalers,\n",
        "          output_time_length=175,\n",
        "          channels=1,\n",
        "          snr_db=SNRdB,\n",
        "          subset=False,\n",
        "          batch_size=4\n",
        "      )\n",
        "\n",
        "    print(f\"Training set size: {len(test_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(test_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"pip install --upgrade torchmetrics\")"
      ],
      "metadata": {
        "id": "FELMtw5c06DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsxwPLMc5dYW"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.testing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwNlkhm35dYW"
      },
      "outputs": [],
      "source": [
        "if load_dataframe:\n",
        "  df_subset = pd.read_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulf6mbLC5dYX"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a large amount of data for a general L1 score to be recorded as an overall performance"
      ],
      "metadata": {
        "id": "YD7pkqtunEY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not load_dataframe:\n",
        "  criterion = nn.L1Loss()\n",
        "  loss = test_model_gpu(model, test_loader.train_loader, criterion, scalers)\n",
        "  print(f\"Test Loss: {loss}\")"
      ],
      "metadata": {
        "id": "jSuv1g7ilp8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the val split as data for the more processing intensive df_eval generation, for a more in depth performance analysis"
      ],
      "metadata": {
        "id": "fKBDP-1mnLEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeAt79Ep5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  criterion = nn.L1Loss()\n",
        "  loss, df_eval = test_model(model, test_loader.val_loader, criterion, scalers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5upsUwE65dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Assuming `df` is your original dataframe\n",
        "  #df_eval[\"Improvement\"] = df_eval[\"l1_outvstar\"] df_eval[\"l1_invstar\"]  # Higher SDR is better\n",
        "  subset_columns = [\"instance\", \"l1_invstar\", \"l1_outvstar\", \"l1_invstar_4k\", \"l1_outvstar_4k\", \"l1_invstar_full\", \"l1_outvstar_full\",  \"filename\", \"snr_db\"] #\"Improvement\"]\n",
        "  df_subset = df_eval#[subset_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_u803Xb5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Create a function to map filename to a class\n",
        "  def get_class_from_filename(filename, classes):\n",
        "      for keyword in classes:\n",
        "          if keyword in filename:\n",
        "              return keyword\n",
        "      return 'Unknown'  # Default if no match found\n",
        "\n",
        "  df_subset[['filename_audio', 'filename_noise']] = pd.DataFrame(df_subset['filename'].tolist(), index=df_subset.index)\n",
        "  df_subset['filename_audio'] = df_subset['filename_audio'].apply(lambda x: x.decode('utf-8'))\n",
        "  df_subset['filename_noise'] = df_subset['filename_noise'].apply(lambda x: x.decode('utf-8'))\n",
        "\n",
        "  classes = ['mixture', 'vocals', 'drums', 'guitar', 'bass', 'piano', 'electric_guitar', 'acoustic_guitar', 'synthesizer', 'strings', 'brass']\n",
        "  df_subset['audio_class'] = df_subset['filename_audio'].apply(lambda x: get_class_from_filename(x, classes))\n",
        "\n",
        "  classes = ['0707', 'Rain', 'Crowd', 'Water', 'Ice']\n",
        "  df_subset['noise_class'] = df_subset['filename_noise'].apply(lambda x: get_class_from_filename(x, classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0soXqrD5dYX"
      },
      "outputs": [],
      "source": [
        "df_subset[\"Improvement_L1\"] = df_subset[\"l1_invstar\"] - df_subset[\"l1_outvstar\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_4k\"] = df_subset[\"l1_invstar_4k\"] - df_subset[\"l1_outvstar_4k\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_full\"] = df_subset[\"l1_invstar_full\"] - df_subset[\"l1_outvstar_full\"]  # Lower L1 loss is better"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "EZ9ycQIbJdP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0T5zh3S5dYY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set minimal theme\n",
        "sns.set_theme(style=\"white\", font_scale=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "df_eval = df_subset.copy()\n",
        "\n",
        "# Round SNR to the nearest 2.5 dB\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db\"] / 2.5).round() * 2.5\n",
        "\n",
        "def compute_stats(df, class_col):\n",
        "    grouped = df.groupby([\"snr_db_rounded\", class_col])[\"Improvement_L1\"]\n",
        "    stats = grouped.agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
        "    stats.rename(columns={\n",
        "        \"mean\": \"mean_improvement\",\n",
        "        \"std\": \"std_improvement\",\n",
        "        \"count\": \"count\"\n",
        "    }, inplace=True)\n",
        "    return stats\n",
        "\n",
        "df_audio_stats = compute_stats(df_eval, \"audio_class\")\n",
        "df_noise_stats = compute_stats(df_eval, \"noise_class\")\n"
      ],
      "metadata": {
        "id": "ZOLAfH0KKupK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Calculate weighted mean and std using counts\n",
        "df_noise_stats[\"weighted_var\"] = df_noise_stats[\"std_improvement\"]**2 * df_noise_stats[\"count\"]\n",
        "\n",
        "grouped_all = df_noise_stats.groupby(\"snr_db_rounded\").agg(\n",
        "    mean_improvement=(\"mean_improvement\", lambda x: np.average(x, weights=df_noise_stats.loc[x.index, \"count\"])),\n",
        "    std_improvement=(\"weighted_var\", lambda x: np.sqrt(np.sum(x) / np.sum(df_noise_stats.loc[x.index, \"count\"]))),\n",
        "    total_count=(\"count\", \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "# Filter \"Crowd\" class\n",
        "crowd_df = df_noise_stats[df_noise_stats[\"noise_class\"] == \"Crowd\"]\n",
        "\n",
        "# Plot weighted average\n",
        "plt.plot(\n",
        "    grouped_all[\"snr_db_rounded\"],\n",
        "    grouped_all[\"mean_improvement\"],\n",
        "    marker=\"o\",\n",
        "    label=\"Weighted Mean (All Classes)\",\n",
        "    color=\"steelblue\"\n",
        ")\n",
        "plt.errorbar(\n",
        "    grouped_all[\"snr_db_rounded\"],\n",
        "    grouped_all[\"mean_improvement\"],\n",
        "    yerr=grouped_all[\"std_improvement\"],\n",
        "    fmt='none',\n",
        "    capsize=3,\n",
        "    color=\"steelblue\",\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "offset = 0.25\n",
        "# --- Plot \"Crowd\" noise class (with slight offset) ---\n",
        "plt.plot(\n",
        "    crowd_df[\"snr_db_rounded\"] + offset,\n",
        "    crowd_df[\"mean_improvement\"],\n",
        "    marker=\"s\",\n",
        "    label=\"Crowd Noise\",\n",
        "    color=\"darkorange\"\n",
        ")\n",
        "plt.errorbar(\n",
        "    crowd_df[\"snr_db_rounded\"] + offset,\n",
        "    crowd_df[\"mean_improvement\"],\n",
        "    yerr=crowd_df[\"std_improvement\"],\n",
        "    fmt='none',\n",
        "    capsize=3,\n",
        "    color=\"darkorange\",\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.xlabel(\"SNR (dB, rounded to nearest 2.5)\")\n",
        "plt.ylabel(\"Mean Improvement (L1)\")\n",
        "plt.title(\"Mean Improvement vs SNR\\n(Weighted Overall vs Crowd Noise)\")\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.ylim((-0.2, 0.4))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_tiDsI-Mbo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculate and clean labels\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db\"] / 2.5).round() * 2.5\n",
        "\n",
        "# Clean string labels and keep mapping for sorting\n",
        "df_eval[\"snr_db_rounded_str\"] = df_eval[\"snr_db_rounded\"].apply(\n",
        "    lambda x: f\"{x:.1f}\".rstrip('0').rstrip('.') if '.' in f\"{x:.1f}\" else f\"{int(x)}\"\n",
        ")\n",
        "\n",
        "# Sort labels numerically\n",
        "ordered_snrs = sorted(df_eval[\"snr_db_rounded\"].unique())\n",
        "ordered_labels = [f\"{x:.1f}\".rstrip('0').rstrip('.') if '.' in f\"{x:.1f}\" else f\"{int(x)}\" for x in ordered_snrs]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(\n",
        "    data=df_eval,\n",
        "    x=\"snr_db_rounded_str\",\n",
        "    y=\"Improvement_L1\",\n",
        "    hue=\"noise_class\",\n",
        "    palette=\"tab10\",\n",
        "    order=ordered_labels  # ✅ apply numeric order\n",
        ")\n",
        "\n",
        "plt.xlabel(\"SNR (dB, rounded to nearest 2.5)\")\n",
        "plt.ylabel(\"Improvement (L1)\")\n",
        "plt.title(\"Distribution of Improvement vs SNR by Noise Class (Box Plot)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.ylim((-0.2, 0.4))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "64vCfanPN_bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(\n",
        "    data=df_eval,\n",
        "    x=\"snr_db_rounded_str\",\n",
        "    y=\"Improvement_L1\",\n",
        "    hue=\"noise_class\",\n",
        "    palette=\"tab10\",\n",
        "    order=ordered_labels,\n",
        "    showfliers=False,  # Hide outliers\n",
        "    linewidth=0.8,\n",
        "    width=0.6\n",
        ")\n",
        "\n",
        "plt.xlabel(\"SNR (dB, rounded to nearest 2.5)\")\n",
        "plt.ylabel(\"Improvement (L1)\")\n",
        "plt.title(\"Distribution of Improvement vs SNR by Noise Class (Box Plot)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.ylim((-0.2, 0.4))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "939PcZEGeK47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.catplot(\n",
        "    data=df_eval,\n",
        "    x=\"snr_db_rounded_str\",\n",
        "    y=\"Improvement_L1\",\n",
        "    col=\"noise_class\",\n",
        "    kind=\"box\",\n",
        "    col_wrap=3,\n",
        "    order=ordered_labels,\n",
        "    color=\"skyblue\",  # ✅ uniform color for all boxes\n",
        "    height=4,\n",
        "    aspect=1\n",
        ")\n",
        "\n",
        "# Titles, labels, limits\n",
        "g.set_titles(col_template=\"{col_name}\")\n",
        "g.set_axis_labels(\"SNR (dB)\", \"Improvement (SDR)\")\n",
        "g.set(ylim=(-0.2, 0.6))\n",
        "\n",
        "# ✅ Add horizontal gridlines to all facets\n",
        "for ax in g.axes.flat:\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BO5y7V06cMq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o19dHk1o5dYZ"
      },
      "outputs": [],
      "source": [
        "# Save subset dataframe\n",
        "df_subset.to_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGHis62M5dYZ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "# Delete large variables\n",
        "\n",
        "# Force garbage collection\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDQGuIQt5dYX"
      },
      "outputs": [],
      "source": [
        "def threshold_spectrogram(spectrogram, threshold):\n",
        "    \"\"\"\n",
        "    Zeroes out all values in the spectrogram that are below the given threshold.\n",
        "\n",
        "    Args:\n",
        "        spectrogram (np.ndarray): Input 2D array.\n",
        "        threshold (float): The threshold value.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The processed spectrogram with values below threshold set to zero.\n",
        "    \"\"\"\n",
        "    spectrogram = np.where(spectrogram >= threshold, spectrogram, 0)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbUP9Kqz5dYX"
      },
      "source": [
        "## View Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r24uLUeL5dYX"
      },
      "outputs": [],
      "source": [
        "sampling_rate = 44100  # 44.1 kHz audio\n",
        "n_fft = 2048  # Adjust this for better resolution\n",
        "freqs = np.linspace(0, sampling_rate / 2, n_fft // 2 + 1)  # STFT frequency bins\n",
        "\n",
        "# Find indices corresponding to 0–4000 Hz\n",
        "min_freq, max_freq = 0, 4000\n",
        "freq_indices = np.where((freqs >= min_freq) & (freqs <= max_freq))[0]\n",
        "\n",
        "# in spectrogram\n",
        "index = 40\n",
        "\n",
        "snr_db = np.array(df_subset.loc[index, \"snr_db\"])\n",
        "print(snr_db)\n",
        "\n",
        "# lets evaluate this from a l1 loss perspective\n",
        "# reconstruct spectrogram\n",
        "out_spectrogram = np.array(df_subset.loc[index, \"out_track\"][0])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_hf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][1]), df_subset.loc[index, \"metadata\"][\"hf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_mf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][2]), df_subset.loc[index, \"metadata\"][\"mf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_lf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][3]), df_subset.loc[index, \"metadata\"][\"lf_shape\"])\n",
        "out_spec_copy = out_spectrogram\n",
        "\n",
        "out_spectrogram = threshold_spectrogram(out_spectrogram, np.mean(out_spectrogram)*0.75)\n",
        "\n",
        "# out, with no join\n",
        "out_track = np.array(df_subset.loc[index, \"out_track\"])[0]\n",
        "\n",
        "# out spectrogram\n",
        "in_spectrogram = df_subset.loc[index, \"in_track\"][0]\n",
        "\n",
        "# target\n",
        "tar_track = np.array(df_subset.loc[index, \"tar_track\"])[0]\n",
        "\n",
        "# inverse normalisation to 0 - 1\n",
        "out_spectrogram = (out_spectrogram - 0.5) * 2\n",
        "out_track = (out_track - 0.5) * 2\n",
        "in_spectrogram = (in_spectrogram - 0.5) * 2\n",
        "tar_track = (tar_track - 0.5) * 2\n",
        "\n",
        "# Inverse standardisation\n",
        "input_temp = tar_track\n",
        "in_spectrogram = scalers[\"input_features_spectrogram\"].inverse_transform(in_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "out_spectrogram = scalers[\"target_features_spectrogram\"].inverse_transform(out_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "out_track = scalers[\"target_features_spectrogram\"].inverse_transform(out_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "tar_track = scalers[\"target_features_spectrogram\"].inverse_transform(tar_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "# plot things\n",
        "# Plot spectrograms\n",
        "fig, axes = plt.subplots(4, 1, figsize=(15, 15))\n",
        "\n",
        "axes[0].imshow(in_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[0].set_title(\"Noisy Input (Log Scale)\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].set_ylim((1, 1000))\n",
        "\n",
        "axes[1].imshow(out_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[1].set_title(\"Denoised Output (Log Scale) - reconstructed\")\n",
        "axes[1].set_yscale(\"log\")\n",
        "axes[1].set_ylim((1, 1000))\n",
        "\n",
        "axes[2].imshow(out_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[2].set_title(\"Denoised Output (Log Scale)\")\n",
        "axes[2].set_yscale(\"log\")\n",
        "axes[2].set_ylim((1, 1000))\n",
        "\n",
        "axes[3].imshow(tar_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[3].set_title(\"Clean Target (Log Scale)\")\n",
        "axes[3].set_yscale(\"log\")\n",
        "axes[3].set_ylim((1, 1000))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DsyfJNd5dYY"
      },
      "outputs": [],
      "source": [
        "def magphase_to_waveform(magnitude, phase, audio_length=44100):\n",
        "    \"\"\"\n",
        "    Converts a spectrogram image back into an audio waveform.\n",
        "\n",
        "    Parameters:\n",
        "        image (np.array): Spectrogram image (3 channels).\n",
        "        sr (int): Sampling rate.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Reconstructed audio waveform.\n",
        "    \"\"\"\n",
        "    stft = magnitude * np.exp(1j * phase)\n",
        "    return librosa.istft(stft, length=audio_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SloKTdbC5dYY"
      },
      "outputs": [],
      "source": [
        "import scipy.io.wavfile\n",
        "from google.colab import files\n",
        "import librosa\n",
        "\n",
        "# output waveform\n",
        "phase = df_subset.loc[index, \"metadata\"][\"phase\"]\n",
        "#phase = scalers[\"input_features_phase\"].inverse_transform(phase.reshape(1, -1)).reshape(input_temp.shape)\n",
        "print(np.max(phase))\n",
        "print(np.min(phase))\n",
        "\n",
        "# reverse log scale\n",
        "out_spectrogram = librosa.db_to_amplitude(out_spectrogram)\n",
        "signal = magphase_to_waveform(out_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"denoised_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "tar_track = librosa.db_to_amplitude(tar_track)\n",
        "signal = magphase_to_waveform(tar_track, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "in_spectrogram = librosa.db_to_amplitude(in_spectrogram)\n",
        "signal = magphase_to_waveform(in_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"noisy_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLO0zc_M5dYY"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvagagkU5dYZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnesqFwi5dYZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}