{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MLErdk55dYT"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uW1R-NqaTB",
        "outputId": "6a130f7a-7a23-4294-e924-dc9e74d9c181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ohND2-qaTC",
        "outputId": "e06a8645-c26e-43bd-c74e-f1d79e2c7202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout bandchannels\")\n",
        "    os.system(\"git pull origin bandchannels\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin bandchannels\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7TDd5eSmqaTC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjJuGbbf5dYU"
      },
      "source": [
        "Notes on testing:\n",
        "1. SDR is missing as a metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMfisrfe5dYV"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torchvision.models._utils import IntermediateLayerGetter"
      ],
      "metadata": {
        "id": "oK-oTZXM7DR0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.models.UNetConv10mask import UNetConv10\n",
        "from audioautoencoder.training import DenoisingLoader"
      ],
      "metadata": {
        "id": "Sekt_USu7LW-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'UNetConv10_mask'\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdB = SNRdB_load\n",
        "load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "\n",
        "\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ],
      "metadata": {
        "id": "YBvUL2h17hku"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8fMr_OK5dYV",
        "outputId": "22c00588-40da-4b09-daa5-1c0d96c13c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from /content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_UNetConv10_mask_-10-10/Autoencodermodel_earlystopping.pth\n",
            "Loaded Model\n",
            "torch.Size([1, 4, 1025, 175])\n"
          ]
        }
      ],
      "source": [
        "# Add the custom class to the safe globals list\n",
        "torch.serialization.add_safe_globals([UNetConv10])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetConv10().to(device)\n",
        "\n",
        "# Now load your checkpoint normally\n",
        "denoiser = DenoisingLoader(model, load_path)\n",
        "model = denoiser.model\n",
        "print('Loaded Model')\n",
        "\n",
        "# Example input (batch_size=1, channels=2, height=1025, width=175)\n",
        "noisy_input = torch.randn(1, 9, 1025, 175)\n",
        "\n",
        "denoised_output = denoiser.denoise(noisy_input)\n",
        "print(denoised_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JHMoC4jb5dYW"
      },
      "outputs": [],
      "source": [
        "IMPORT_TEST_NOISY = True\n",
        "load_dataframe = True\n",
        "max_file_size_gb = 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.datasets.utils import *\n",
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.data_management import *\n",
        "from audioautoencoder.generate_dataset import *"
      ],
      "metadata": {
        "id": "NaguRh9whjqk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_diffusion = False\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "#load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = ['sep_features', 'all-noise_features', 'all-noise_features_2'][2] # sep\n",
        "\n",
        "scaler_file = load_path + \"scalers.pkl\"  # Static filename since it's unique per run\n",
        "os.makedirs(os.path.dirname(scaler_file), exist_ok=True)\n",
        "source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "source_path = source_folder + \"test/\""
      ],
      "metadata": {
        "id": "hpzrft8bjZ7x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "O9Z6zhuo5dYW",
        "outputId": "a5f773d4-031e-464a-c3b0-1919f55dd0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_060720.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_061250.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_064432.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_060243.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_074949.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_101841.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_084859.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_090214.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_113029.h5', '/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_081949.h5']\n",
            "Created new file: /content/SNRdB_-10-10/test/combined_000.h5\n",
            "Progress: 1.14 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_061250.h5\n",
            "Progress: 2.08 GB - Processing /content/drive/MyDrive/Datasets/Music-Noise/SNRdB_all-noise_features_2/SNRdB_-10-10/test/test-SNRdB_-10-10_20250328_064432.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 107] Transport endpoint is not connected",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                     \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b7f8146a061e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIMPORT_TEST_NOISY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcombine_h5_files_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_file_size_gb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_file_size_gb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/generate_dataset.py\u001b[0m in \u001b[0;36mcombine_h5_files_features\u001b[0;34m(h5_folder_path, output_folder_path, max_file_size_gb, chunk_size, dst)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# as per deep research, first copy the file to disk, as a temporary file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Copy file from Drive to local storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;31m# input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"
          ]
        }
      ],
      "source": [
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if IMPORT_TEST_NOISY:\n",
        "  if not os.path.exists(destination_path):\n",
        "    combine_h5_files_features(source_path, destination_path, max_file_size_gb=max_file_size_gb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol6z8f0O5dYW"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.datasets.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/combined_000.h5\""
      ],
      "metadata": {
        "id": "tFpOxFIimnc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guDB9wtk5dYW"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(scaler_file):\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "else:\n",
        "    print(\"Training new scalers...\")\n",
        "    scalers = train_scalers_separation(dataset_path, sample_size=8000)\n",
        "    save_scalers(scalers, scaler_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bKvGXxi5dYW"
      },
      "outputs": [],
      "source": [
        "if IMPORT_TEST_NOISY:\n",
        "    save_path = source_path + \"combined_000.h5\"\n",
        "    print(\"Loading existing scalers...\")\n",
        "    scalers = load_scalers(scaler_file)\n",
        "    test_loader = ChannelDatasetLoader(\n",
        "          dataset_path=save_path,\n",
        "          scalers=scalers,\n",
        "          output_time_length=175,\n",
        "          channels=1,\n",
        "          snr_db=SNRdB,\n",
        "          subset=True,\n",
        "          batch_size=4\n",
        "      )\n",
        "\n",
        "    print(f\"Training set size: {len(test_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(test_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsxwPLMc5dYW"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.testing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwNlkhm35dYW"
      },
      "outputs": [],
      "source": [
        "if load_dataframe:\n",
        "  df_subset = pd.read_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulf6mbLC5dYX"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system(\"pip install --upgrade torchmetrics\")"
      ],
      "metadata": {
        "id": "F_2ljWe1pzI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeAt79Ep5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  criterion = nn.L1Loss()\n",
        "  loss, df_eval = test_model(model, test_loader.train_loader, criterion, scalers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5upsUwE65dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Assuming `df` is your original dataframe\n",
        "  #df_eval[\"Improvement\"] = df_eval[\"l1_outvstar\"] df_eval[\"l1_invstar\"]  # Higher SDR is better\n",
        "  subset_columns = [\"instance\", \"l1_invstar\", \"l1_outvstar\", \"l1_invstar_4k\", \"l1_outvstar_4k\", \"l1_invstar_full\", \"l1_outvstar_full\",  \"filename\", \"snr_db\"] #\"Improvement\"]\n",
        "  df_subset = df_eval#[subset_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_u803Xb5dYX"
      },
      "outputs": [],
      "source": [
        "if not load_dataframe:\n",
        "  # Create a function to map filename to a class\n",
        "  def get_class_from_filename(filename, classes):\n",
        "      for keyword in classes:\n",
        "          if keyword in filename:\n",
        "              return keyword\n",
        "      return 'Unknown'  # Default if no match found\n",
        "\n",
        "  df_subset[['filename_audio', 'filename_noise']] = pd.DataFrame(df_subset['filename'].tolist(), index=df_subset.index)\n",
        "  df_subset['filename_audio'] = df_subset['filename_audio'].apply(lambda x: x.decode('utf-8'))\n",
        "  df_subset['filename_noise'] = df_subset['filename_noise'].apply(lambda x: x.decode('utf-8'))\n",
        "\n",
        "  classes = ['mixture', 'vocals', 'drums', 'guitar', 'bass', 'piano', 'electric_guitar', 'acoustic_guitar', 'synthesizer', 'strings', 'brass']\n",
        "  df_subset['audio_class'] = df_subset['filename_audio'].apply(lambda x: get_class_from_filename(x, classes))\n",
        "\n",
        "  classes = ['0707', 'Rain', 'Crowd', 'Water', 'Ice']\n",
        "  df_subset['noise_class'] = df_subset['filename_noise'].apply(lambda x: get_class_from_filename(x, classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0soXqrD5dYX"
      },
      "outputs": [],
      "source": [
        "df_subset[\"Improvement_L1\"] = df_subset[\"l1_invstar\"] - df_subset[\"l1_outvstar\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_4k\"] = df_subset[\"l1_invstar_4k\"] - df_subset[\"l1_outvstar_4k\"]  # Lower L1 loss is better\n",
        "df_subset[\"Improvement_L1_full\"] = df_subset[\"l1_invstar_full\"] - df_subset[\"l1_outvstar_full\"]  # Lower L1 loss is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDQGuIQt5dYX"
      },
      "outputs": [],
      "source": [
        "def threshold_spectrogram(spectrogram, threshold):\n",
        "    \"\"\"\n",
        "    Zeroes out all values in the spectrogram that are below the given threshold.\n",
        "\n",
        "    Args:\n",
        "        spectrogram (np.ndarray): Input 2D array.\n",
        "        threshold (float): The threshold value.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The processed spectrogram with values below threshold set to zero.\n",
        "    \"\"\"\n",
        "    spectrogram = np.where(spectrogram >= threshold, spectrogram, 0)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbUP9Kqz5dYX"
      },
      "source": [
        "## View Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r24uLUeL5dYX"
      },
      "outputs": [],
      "source": [
        "sampling_rate = 44100  # 44.1 kHz audio\n",
        "n_fft = 2048  # Adjust this for better resolution\n",
        "freqs = np.linspace(0, sampling_rate / 2, n_fft // 2 + 1)  # STFT frequency bins\n",
        "\n",
        "# Find indices corresponding to 0–4000 Hz\n",
        "min_freq, max_freq = 0, 4000\n",
        "freq_indices = np.where((freqs >= min_freq) & (freqs <= max_freq))[0]\n",
        "\n",
        "# in spectrogram\n",
        "index = 40\n",
        "\n",
        "snr_db = np.array(df_subset.loc[index, \"snr_db\"])\n",
        "print(snr_db)\n",
        "\n",
        "# lets evaluate this from a l1 loss perspective\n",
        "# reconstruct spectrogram\n",
        "out_spectrogram = np.array(df_subset.loc[index, \"out_track\"][0])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_hf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][1]), df_subset.loc[index, \"metadata\"][\"hf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_mf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][2]), df_subset.loc[index, \"metadata\"][\"mf_shape\"])\n",
        "out_spectrogram[df_subset.loc[index, \"metadata\"][\"freq_indices_lf\"], :] = resample_feature(np.array(df_subset.loc[index, \"out_track\"][3]), df_subset.loc[index, \"metadata\"][\"lf_shape\"])\n",
        "out_spec_copy = out_spectrogram\n",
        "\n",
        "out_spectrogram = threshold_spectrogram(out_spectrogram, np.mean(out_spectrogram)*0.75)\n",
        "\n",
        "# out, with no join\n",
        "out_track = np.array(df_subset.loc[index, \"out_track\"])[0]\n",
        "\n",
        "# out spectrogram\n",
        "in_spectrogram = df_subset.loc[index, \"in_track\"][0]\n",
        "\n",
        "# target\n",
        "tar_track = np.array(df_subset.loc[index, \"tar_track\"])[0]\n",
        "\n",
        "# inverse normalisation to 0 - 1\n",
        "out_spectrogram = (out_spectrogram - 0.5) * 3\n",
        "out_track = (out_track - 0.5) * 3\n",
        "in_spectrogram = (in_spectrogram - 0.5) * 3\n",
        "tar_track = (tar_track - 0.5) * 3\n",
        "\n",
        "# Inverse standardisation\n",
        "input_temp = tar_track\n",
        "in_spectrogram = scalers[\"input_features_spectrogram\"].inverse_transform(in_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "out_spectrogram = scalers[\"target_features_spectrogram\"].inverse_transform(out_spectrogram.reshape(1, -1)).reshape(input_temp.shape)\n",
        "out_track = scalers[\"target_features_spectrogram\"].inverse_transform(out_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "tar_track = scalers[\"target_features_spectrogram\"].inverse_transform(tar_track.reshape(1, -1)).reshape(input_temp.shape)\n",
        "\n",
        "# plot things\n",
        "# Plot spectrograms\n",
        "fig, axes = plt.subplots(4, 1, figsize=(15, 15))\n",
        "\n",
        "axes[0].imshow(in_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[0].set_title(\"Noisy Input (Log Scale)\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].set_ylim((1, 1000))\n",
        "\n",
        "axes[1].imshow(out_spectrogram, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[1].set_title(\"Denoised Output (Log Scale) - reconstructed\")\n",
        "axes[1].set_yscale(\"log\")\n",
        "axes[1].set_ylim((1, 1000))\n",
        "\n",
        "axes[2].imshow(out_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[2].set_title(\"Denoised Output (Log Scale)\")\n",
        "axes[2].set_yscale(\"log\")\n",
        "axes[2].set_ylim((1, 1000))\n",
        "\n",
        "axes[3].imshow(tar_track, aspect=\"auto\", cmap=\"magma\", origin=\"lower\")\n",
        "axes[3].set_title(\"Clean Target (Log Scale)\")\n",
        "axes[3].set_yscale(\"log\")\n",
        "axes[3].set_ylim((1, 1000))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DsyfJNd5dYY"
      },
      "outputs": [],
      "source": [
        "def magphase_to_waveform(magnitude, phase, audio_length=44100):\n",
        "    \"\"\"\n",
        "    Converts a spectrogram image back into an audio waveform.\n",
        "\n",
        "    Parameters:\n",
        "        image (np.array): Spectrogram image (3 channels).\n",
        "        sr (int): Sampling rate.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Reconstructed audio waveform.\n",
        "    \"\"\"\n",
        "    stft = magnitude * np.exp(1j * phase)\n",
        "    return librosa.istft(stft, length=audio_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SloKTdbC5dYY"
      },
      "outputs": [],
      "source": [
        "import scipy.io.wavfile\n",
        "from google.colab import files\n",
        "import librosa\n",
        "\n",
        "# output waveform\n",
        "phase = df_subset.loc[index, \"metadata\"][\"phase\"]\n",
        "#phase = scalers[\"input_features_phase\"].inverse_transform(phase.reshape(1, -1)).reshape(input_temp.shape)\n",
        "print(np.max(phase))\n",
        "print(np.min(phase))\n",
        "\n",
        "# reverse log scale\n",
        "out_spectrogram = librosa.db_to_amplitude(out_spectrogram)\n",
        "signal = magphase_to_waveform(out_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"denoised_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "tar_track = librosa.db_to_amplitude(tar_track)\n",
        "signal = magphase_to_waveform(tar_track, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)\n",
        "\n",
        "in_spectrogram = librosa.db_to_amplitude(in_spectrogram)\n",
        "signal = magphase_to_waveform(in_spectrogram, phase, 44100 * 2)\n",
        "\n",
        "# Save as WAV file\n",
        "output_filename = f\"noisy_audio_{index}:{snr_db}.wav\"\n",
        "scipy.io.wavfile.write(output_filename, rate=44100, data=signal)  # 16-bit PCM\n",
        "\n",
        "# Download the file\n",
        "files.download(output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLO0zc_M5dYY"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0T5zh3S5dYY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set minimal theme\n",
        "sns.set_theme(style=\"white\", font_scale=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NfI_d_s5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "df_eval = df_subset\n",
        "\n",
        "# Round SNR values to the nearest 0.5 to reduce noise\n",
        "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
        "\n",
        "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
        "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
        "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1\"].mean()\n",
        "\n",
        "# Line plot colored by 'audio_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Line plot colored by 'noise_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqUfxeGB5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "df_eval = df_subset\n",
        "\n",
        "# Round SNR values to the nearest 0.5 to reduce noise\n",
        "df_eval[\"snr_db_rounded\"] = df_eval[\"snr_db\"].round(1)  # Rounds to 1 decimal place\n",
        "df_eval[\"snr_db_rounded\"] = (df_eval[\"snr_db_rounded\"] * 2).round() / 2  # Ensures nearest 0.5\n",
        "\n",
        "# Group by rounded SNR and audio/noise class, then compute mean improvement\n",
        "df_audio_avg = df_eval.groupby([\"snr_db_rounded\", \"audio_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
        "df_noise_avg = df_eval.groupby([\"snr_db_rounded\", \"noise_class\"], as_index=False)[\"Improvement_L1_4k\"].mean()\n",
        "\n",
        "# Line plot colored by 'audio_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_audio_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"audio_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Audio Class)\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Line plot colored by 'noise_class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_noise_avg, x=\"snr_db_rounded\", y=\"Improvement_L1_4k\", hue=\"noise_class\", palette=\"tab10\", marker=\"o\")\n",
        "plt.xlabel(\"SNR (dB)\")\n",
        "plt.ylabel(\"Mean Improvement (SDR)\")\n",
        "plt.title(\"Mean Improvement vs SNR (Rounded to 0.5, Colored by Noise Class)\")\n",
        "plt.legend(title=\"Noise Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Iy5VG75dYY"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = df_subset\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.boxplot(x=\"noise_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df)\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.ylim(-0.5, 0.5)\n",
        "plt.savefig(output_path + f\"boxplot_all_L1.png\")\n",
        "plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter for 'crowd' noise class\n",
        "df_crowd = df_subset[df_subset[\"noise_class\"] == \"Crowd\"].copy()\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sns.boxplot(x=\"audio_class\", y=\"Improvement_L1\", hue=\"audio_class\", data=df_crowd)\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks()\n",
        "#plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.ylim(-0.5, 0.5)\n",
        "plt.savefig(output_path + f\"boxplot_crowd_L1.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWIZ9QsG5dYY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you already have the dataframe loaded in `df`\n",
        "# df = pd.read_csv('your_data.csv')  # Uncomment if loading from CSV\n",
        "df = df_subset\n",
        "\n",
        "# You can also add visualization here if you want to dive deeper\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a more interpretable colormap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['l1_invstar', 'l1_outvstar', 'snr_db', 'Improvement_L1']].corr(),\n",
        "            annot=True, cmap='mako', fmt=\".2f\", vmin=-1, vmax=1, center=0)\n",
        "\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o19dHk1o5dYZ"
      },
      "outputs": [],
      "source": [
        "# Save subset dataframe\n",
        "df_subset.to_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGHis62M5dYZ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "# Delete large variables\n",
        "del df_subset, df_eval, df\n",
        "\n",
        "# Force garbage collection\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvagagkU5dYZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnesqFwi5dYZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}