{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owcrW1IV0Eox"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "\n",
        "1. considering how much upsampling is going in in each channels for accounting for the perception of each frequency band... I could get away with downsampling the whole thing in the frequency direction by a factor of 4, 8 or even 16, reducing the sample rate post upsample.... this could worth for both the masking model and the diffusion model easily, reducing the image size from (1024, 175) to (128, 175)\n",
        "\n",
        "2. I need to edit the levels of the training data so that anything where the signal is greater than 1 (due to high noise), should be normalised to 1\n",
        "\n",
        "3. I may need to connect the features as images next to eachother, instead of channels in an input as the channels are cross effecting eachother in a negative way (where audio shoule be let through in one channel but bloced in one it is getting confused or assuming a relationship between channels when there is none)\n",
        "\n",
        "Next Steps:\n",
        "\n",
        "2. Compare custom res-net model with attention as masking with deeplabv3_resnet50 altered. To complete the project, compare:\n",
        "3. a) Custom simple, b) custom complex, c) deeplabv3_resnet50 d) lraspp_mobilenet_v3_large e) segformer\n",
        "4. maybe change how different samplerate images are concatenated\n",
        "5. stop using cosine anealing as a straight learning rate is better"
      ],
      "metadata": {
        "id": "x_OzgxdWa-aY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uW1R-NqaTB",
        "outputId": "513a7449-cc02-42f3-a268-772b594ec355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ohND2-qaTC",
        "outputId": "abd1001a-6ce3-4e6f-f6f6-374504b6c6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout test-with-features\")\n",
        "    os.system(\"git pull origin test-with-features\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin main\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7TDd5eSmqaTC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zyus8N0Eoy"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.models.UNetRes12 import *\n",
        "from audioautoencoder.models.UNetConv4 import *"
      ],
      "metadata": {
        "id": "UAF0PUg2-C10"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwkxT6OP0Eoz"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReWh6Ybl0Eoz",
        "outputId": "bfaf73fa-8383-48db-a46e-6965f33e332f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output....\n",
            "torch.Size([1, 4, 256, 175])\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1\n",
        "TEST_MODEL = True\n",
        "\n",
        "if TEST_MODEL:\n",
        "  if __name__ == \"__main__\":\n",
        "      x = torch.randn((BATCH_SIZE, 4, 1025 // 4, 175))\n",
        "      model = UNetRes12(in_channels=4, out_channels=4)\n",
        "      #model = UNetConv4(in_channels=4, out_channels=4)\n",
        "      model.eval()\n",
        "      output = model(x)\n",
        "\n",
        "      print('output....')\n",
        "      print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "_r46u9cXkIgV",
        "outputId": "f6c1fc15-05c9-40d0-a220-62baaa9d35a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# For example, if the input size is (batch_size=2, channels=9, height=256, width=256):\n",
        "summary(model, input_size=(2, 4, 1025 // 4, 175))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c_nBwCfNs4e",
        "outputId": "b0141d78-ed69-4bb0-d449-17025964b877"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "UNetRes12                                [2, 4, 256, 175]          --\n",
              "├─Sequential: 1-1                        [2, 32, 128, 88]          --\n",
              "│    └─Conv2d: 2-1                       [2, 32, 128, 88]          1,184\n",
              "│    └─GroupNorm: 2-2                    [2, 32, 128, 88]          64\n",
              "│    └─LeakyReLU: 2-3                    [2, 32, 128, 88]          --\n",
              "│    └─Conv2d: 2-4                       [2, 32, 128, 88]          9,248\n",
              "│    └─GroupNorm: 2-5                    [2, 32, 128, 88]          64\n",
              "│    └─LeakyReLU: 2-6                    [2, 32, 128, 88]          --\n",
              "├─ResLayer: 1-2                          [2, 64, 64, 44]           --\n",
              "│    └─ResBlock: 2-7                     [2, 32, 128, 88]          --\n",
              "│    │    └─GroupNorm: 3-1               [2, 32, 128, 88]          64\n",
              "│    │    └─ReLU: 3-2                    [2, 32, 128, 88]          --\n",
              "│    │    └─Conv2d: 3-3                  [2, 32, 128, 88]          9,248\n",
              "│    │    └─GroupNorm: 3-4               [2, 32, 128, 88]          64\n",
              "│    │    └─ReLU: 3-5                    [2, 32, 128, 88]          --\n",
              "│    │    └─Conv2d: 3-6                  [2, 32, 128, 88]          9,248\n",
              "│    │    └─Dropout: 3-7                 [2, 32, 128, 88]          --\n",
              "│    └─ResBlock: 2-8                     [2, 32, 128, 88]          --\n",
              "│    │    └─GroupNorm: 3-8               [2, 32, 128, 88]          64\n",
              "│    │    └─ReLU: 3-9                    [2, 32, 128, 88]          --\n",
              "│    │    └─Conv2d: 3-10                 [2, 32, 128, 88]          9,248\n",
              "│    │    └─GroupNorm: 3-11              [2, 32, 128, 88]          64\n",
              "│    │    └─ReLU: 3-12                   [2, 32, 128, 88]          --\n",
              "│    │    └─Conv2d: 3-13                 [2, 32, 128, 88]          9,248\n",
              "│    │    └─Dropout: 3-14                [2, 32, 128, 88]          --\n",
              "│    └─Conv2d: 2-9                       [2, 64, 64, 44]           18,496\n",
              "├─ResLayer: 1-3                          [2, 128, 32, 22]          --\n",
              "│    └─ResBlock: 2-10                    [2, 64, 64, 44]           --\n",
              "│    │    └─GroupNorm: 3-15              [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-16                   [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-17                 [2, 64, 64, 44]           36,928\n",
              "│    │    └─GroupNorm: 3-18              [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-19                   [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-20                 [2, 64, 64, 44]           36,928\n",
              "│    │    └─Dropout: 3-21                [2, 64, 64, 44]           --\n",
              "│    └─ResBlock: 2-11                    [2, 64, 64, 44]           --\n",
              "│    │    └─GroupNorm: 3-22              [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-23                   [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-24                 [2, 64, 64, 44]           36,928\n",
              "│    │    └─GroupNorm: 3-25              [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-26                   [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-27                 [2, 64, 64, 44]           36,928\n",
              "│    │    └─Dropout: 3-28                [2, 64, 64, 44]           --\n",
              "│    └─Conv2d: 2-12                      [2, 128, 32, 22]          73,856\n",
              "├─ResLayer: 1-4                          [2, 256, 16, 11]          --\n",
              "│    └─ResBlock: 2-13                    [2, 128, 32, 22]          --\n",
              "│    │    └─GroupNorm: 3-29              [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-30                   [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-31                 [2, 128, 32, 22]          147,584\n",
              "│    │    └─GroupNorm: 3-32              [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-33                   [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-34                 [2, 128, 32, 22]          147,584\n",
              "│    │    └─Dropout: 3-35                [2, 128, 32, 22]          --\n",
              "│    └─Attention: 2-14                   [2, 128, 32, 22]          --\n",
              "│    │    └─Linear: 3-36                 [2, 704, 384]             49,536\n",
              "│    │    └─Linear: 3-37                 [2, 32, 22, 128]          16,512\n",
              "│    └─ResBlock: 2-15                    [2, 128, 32, 22]          --\n",
              "│    │    └─GroupNorm: 3-38              [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-39                   [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-40                 [2, 128, 32, 22]          147,584\n",
              "│    │    └─GroupNorm: 3-41              [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-42                   [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-43                 [2, 128, 32, 22]          147,584\n",
              "│    │    └─Dropout: 3-44                [2, 128, 32, 22]          --\n",
              "│    └─Conv2d: 2-16                      [2, 256, 16, 11]          295,168\n",
              "├─ResLayer: 1-5                          [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-17                    [2, 256, 16, 11]          --\n",
              "│    │    └─GroupNorm: 3-45              [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-46                   [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-47                 [2, 256, 16, 11]          590,080\n",
              "│    │    └─GroupNorm: 3-48              [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-49                   [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-50                 [2, 256, 16, 11]          590,080\n",
              "│    │    └─Dropout: 3-51                [2, 256, 16, 11]          --\n",
              "│    └─ResBlock: 2-18                    [2, 256, 16, 11]          --\n",
              "│    │    └─GroupNorm: 3-52              [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-53                   [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-54                 [2, 256, 16, 11]          590,080\n",
              "│    │    └─GroupNorm: 3-55              [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-56                   [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-57                 [2, 256, 16, 11]          590,080\n",
              "│    │    └─Dropout: 3-58                [2, 256, 16, 11]          --\n",
              "│    └─Conv2d: 2-19                      [2, 512, 8, 6]            1,180,160\n",
              "├─ResLayer: 1-6                          [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-20                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-59              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-60                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-61                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-62              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-63                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-64                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-65                [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-21                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-66              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-67                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-68                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-69              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-70                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-71                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-72                [2, 512, 8, 6]            --\n",
              "├─ResLayer: 1-7                          [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-22                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-73              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-74                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-75                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-76              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-77                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-78                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-79                [2, 512, 8, 6]            --\n",
              "│    └─Attention: 2-23                   [2, 512, 8, 6]            --\n",
              "│    │    └─Linear: 3-80                 [2, 48, 1536]             787,968\n",
              "│    │    └─Linear: 3-81                 [2, 8, 6, 512]            262,656\n",
              "│    └─ResBlock: 2-24                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-82              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-83                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-84                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-85              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-86                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-87                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-88                [2, 512, 8, 6]            --\n",
              "├─ResLayer: 1-8                          [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-25                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-89              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-90                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-91                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-92              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-93                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-94                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-95                [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-26                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-96              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-97                   [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-98                 [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-99              [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-100                  [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-101                [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-102               [2, 512, 8, 6]            --\n",
              "├─EnhancedSkipAttention: 1-9             [2, 512, 8, 6]            --\n",
              "│    └─Sequential: 2-27                  [2, 512, 1, 1]            --\n",
              "│    │    └─AdaptiveAvgPool2d: 3-103     [2, 512, 1, 1]            --\n",
              "│    │    └─Conv2d: 3-104                [2, 256, 1, 1]            131,328\n",
              "│    │    └─ReLU: 3-105                  [2, 256, 1, 1]            --\n",
              "│    │    └─Conv2d: 3-106                [2, 512, 1, 1]            131,584\n",
              "│    │    └─Sigmoid: 3-107               [2, 512, 1, 1]            --\n",
              "│    └─Sequential: 2-28                  [2, 2, 8, 6]              --\n",
              "│    │    └─Conv2d: 3-108                [2, 2, 8, 6]              18,434\n",
              "│    │    └─Sigmoid: 3-109               [2, 2, 8, 6]              --\n",
              "├─ResLayer: 1-10                         [2, 256, 16, 12]          --\n",
              "│    └─ResBlock: 2-29                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-110             [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-111                  [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-112                [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-113             [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-114                  [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-115                [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-116               [2, 512, 8, 6]            --\n",
              "│    └─ResBlock: 2-30                    [2, 512, 8, 6]            --\n",
              "│    │    └─GroupNorm: 3-117             [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-118                  [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-119                [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─GroupNorm: 3-120             [2, 512, 8, 6]            1,024\n",
              "│    │    └─ReLU: 3-121                  [2, 512, 8, 6]            --\n",
              "│    │    └─Conv2d: 3-122                [2, 512, 8, 6]            2,359,808\n",
              "│    │    └─Dropout: 3-123               [2, 512, 8, 6]            --\n",
              "│    └─ConvTranspose2d: 2-31             [2, 256, 16, 12]          524,544\n",
              "├─EnhancedSkipAttention: 1-11            [2, 256, 16, 11]          --\n",
              "│    └─Sequential: 2-32                  [2, 256, 1, 1]            --\n",
              "│    │    └─AdaptiveAvgPool2d: 3-124     [2, 256, 1, 1]            --\n",
              "│    │    └─Conv2d: 3-125                [2, 128, 1, 1]            32,896\n",
              "│    │    └─ReLU: 3-126                  [2, 128, 1, 1]            --\n",
              "│    │    └─Conv2d: 3-127                [2, 256, 1, 1]            33,024\n",
              "│    │    └─Sigmoid: 3-128               [2, 256, 1, 1]            --\n",
              "│    └─Sequential: 2-33                  [2, 2, 16, 11]            --\n",
              "│    │    └─Conv2d: 3-129                [2, 2, 16, 11]            9,218\n",
              "│    │    └─Sigmoid: 3-130               [2, 2, 16, 11]            --\n",
              "├─ResLayer: 1-12                         [2, 128, 32, 22]          --\n",
              "│    └─ResBlock: 2-34                    [2, 256, 16, 11]          --\n",
              "│    │    └─GroupNorm: 3-131             [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-132                  [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-133                [2, 256, 16, 11]          590,080\n",
              "│    │    └─GroupNorm: 3-134             [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-135                  [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-136                [2, 256, 16, 11]          590,080\n",
              "│    │    └─Dropout: 3-137               [2, 256, 16, 11]          --\n",
              "│    └─Attention: 2-35                   [2, 256, 16, 11]          --\n",
              "│    │    └─Linear: 3-138                [2, 176, 768]             197,376\n",
              "│    │    └─Linear: 3-139                [2, 16, 11, 256]          65,792\n",
              "│    └─ResBlock: 2-36                    [2, 256, 16, 11]          --\n",
              "│    │    └─GroupNorm: 3-140             [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-141                  [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-142                [2, 256, 16, 11]          590,080\n",
              "│    │    └─GroupNorm: 3-143             [2, 256, 16, 11]          512\n",
              "│    │    └─ReLU: 3-144                  [2, 256, 16, 11]          --\n",
              "│    │    └─Conv2d: 3-145                [2, 256, 16, 11]          590,080\n",
              "│    │    └─Dropout: 3-146               [2, 256, 16, 11]          --\n",
              "│    └─ConvTranspose2d: 2-37             [2, 128, 32, 22]          131,200\n",
              "├─EnhancedSkipAttention: 1-13            [2, 128, 32, 22]          --\n",
              "│    └─Sequential: 2-38                  [2, 128, 1, 1]            --\n",
              "│    │    └─AdaptiveAvgPool2d: 3-147     [2, 128, 1, 1]            --\n",
              "│    │    └─Conv2d: 3-148                [2, 64, 1, 1]             8,256\n",
              "│    │    └─ReLU: 3-149                  [2, 64, 1, 1]             --\n",
              "│    │    └─Conv2d: 3-150                [2, 128, 1, 1]            8,320\n",
              "│    │    └─Sigmoid: 3-151               [2, 128, 1, 1]            --\n",
              "│    └─Sequential: 2-39                  [2, 2, 32, 22]            --\n",
              "│    │    └─Conv2d: 3-152                [2, 2, 32, 22]            4,610\n",
              "│    │    └─Sigmoid: 3-153               [2, 2, 32, 22]            --\n",
              "├─ResLayer: 1-14                         [2, 64, 64, 44]           --\n",
              "│    └─ResBlock: 2-40                    [2, 128, 32, 22]          --\n",
              "│    │    └─GroupNorm: 3-154             [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-155                  [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-156                [2, 128, 32, 22]          147,584\n",
              "│    │    └─GroupNorm: 3-157             [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-158                  [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-159                [2, 128, 32, 22]          147,584\n",
              "│    │    └─Dropout: 3-160               [2, 128, 32, 22]          --\n",
              "│    └─ResBlock: 2-41                    [2, 128, 32, 22]          --\n",
              "│    │    └─GroupNorm: 3-161             [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-162                  [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-163                [2, 128, 32, 22]          147,584\n",
              "│    │    └─GroupNorm: 3-164             [2, 128, 32, 22]          256\n",
              "│    │    └─ReLU: 3-165                  [2, 128, 32, 22]          --\n",
              "│    │    └─Conv2d: 3-166                [2, 128, 32, 22]          147,584\n",
              "│    │    └─Dropout: 3-167               [2, 128, 32, 22]          --\n",
              "│    └─ConvTranspose2d: 2-42             [2, 64, 64, 44]           32,832\n",
              "├─EnhancedSkipAttention: 1-15            [2, 64, 64, 44]           --\n",
              "│    └─Sequential: 2-43                  [2, 64, 1, 1]             --\n",
              "│    │    └─AdaptiveAvgPool2d: 3-168     [2, 64, 1, 1]             --\n",
              "│    │    └─Conv2d: 3-169                [2, 32, 1, 1]             2,080\n",
              "│    │    └─ReLU: 3-170                  [2, 32, 1, 1]             --\n",
              "│    │    └─Conv2d: 3-171                [2, 64, 1, 1]             2,112\n",
              "│    │    └─Sigmoid: 3-172               [2, 64, 1, 1]             --\n",
              "│    └─Sequential: 2-44                  [2, 2, 64, 44]            --\n",
              "│    │    └─Conv2d: 3-173                [2, 2, 64, 44]            2,306\n",
              "│    │    └─Sigmoid: 3-174               [2, 2, 64, 44]            --\n",
              "├─ResLayer: 1-16                         [2, 32, 128, 88]          --\n",
              "│    └─ResBlock: 2-45                    [2, 64, 64, 44]           --\n",
              "│    │    └─GroupNorm: 3-175             [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-176                  [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-177                [2, 64, 64, 44]           36,928\n",
              "│    │    └─GroupNorm: 3-178             [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-179                  [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-180                [2, 64, 64, 44]           36,928\n",
              "│    │    └─Dropout: 3-181               [2, 64, 64, 44]           --\n",
              "│    └─Attention: 2-46                   [2, 64, 64, 44]           --\n",
              "│    │    └─Linear: 3-182                [2, 2816, 192]            12,480\n",
              "│    │    └─Linear: 3-183                [2, 64, 44, 64]           4,160\n",
              "│    └─ResBlock: 2-47                    [2, 64, 64, 44]           --\n",
              "│    │    └─GroupNorm: 3-184             [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-185                  [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-186                [2, 64, 64, 44]           36,928\n",
              "│    │    └─GroupNorm: 3-187             [2, 64, 64, 44]           128\n",
              "│    │    └─ReLU: 3-188                  [2, 64, 64, 44]           --\n",
              "│    │    └─Conv2d: 3-189                [2, 64, 64, 44]           36,928\n",
              "│    │    └─Dropout: 3-190               [2, 64, 64, 44]           --\n",
              "│    └─ConvTranspose2d: 2-48             [2, 32, 128, 88]          8,224\n",
              "├─Sequential: 1-17                       [2, 4, 255, 175]          --\n",
              "│    └─ConvTranspose2d: 2-49             [2, 32, 255, 175]         9,248\n",
              "│    └─LeakyReLU: 2-50                   [2, 32, 255, 175]         --\n",
              "│    └─Conv2d: 2-51                      [2, 4, 255, 175]          1,156\n",
              "├─Sigmoid: 1-18                          [2, 4, 256, 175]          --\n",
              "==========================================================================================\n",
              "Total params: 48,080,556\n",
              "Trainable params: 48,080,556\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 11.82\n",
              "==========================================================================================\n",
              "Input size (MB): 1.43\n",
              "Forward/backward pass size (MB): 226.45\n",
              "Params size (MB): 192.32\n",
              "Estimated Total Size (MB): 420.21\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smzGryj-0Eoz"
      },
      "source": [
        "## Define Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_wGpwKW0Eo0",
        "outputId": "e11bbccc-188e-43c6-cfe5-e3d7ed5f325d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "from audioautoencoder.plotting import *\n",
        "from audioautoencoder.datasets.utils import *\n",
        "#from audioautoencoder.models.UNetConv10mask import *\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.serialization.add_safe_globals([UNetRes12])\n",
        "model = UNetRes12(in_channels=4, out_channels=4).to(device)\n",
        "\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps1ZBM_H0Eo0",
        "outputId": "be8c5cec-1cb2-4962-8e5b-7ec190b5dea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.0001\n",
            "SNRdB: [-10, 10]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "train = True\n",
        "LOAD_DATA = True\n",
        "load_model = True\n",
        "\n",
        "# --------------- Main Execution parameters ---------------\n",
        "model_name = 'UNetRes12'\n",
        "train_diffusion = False\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "load_trigger = [load_model]\n",
        "#load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = 'remapped-signal-level' # sep\n",
        "\n",
        "# parameters\n",
        "learning_rates = [1e-4] # 1e-4 for re0training?, 1e-3 for training? # lowered learning rate for\n",
        "                        # when the loss explodes after the learning rate increases, it means dont increase the learning rate too much\n",
        "base_lr=1e-5\n",
        "max_lr=learning_rates[i]\n",
        "gamma=0.8\n",
        "\n",
        "# data params\n",
        "max_file_size_gb = 1\n",
        "IMPORT_TRAIN_NOISY = train\n",
        "batch_size = 4\n",
        "num_workers = 1\n",
        "\n",
        "# training params\n",
        "load = load_trigger[i]\n",
        "warm_start = True\n",
        "epochs = 100\n",
        "accumulation_steps = int((512*2)/batch_size)\n",
        "\n",
        "SNRdB = SNRdBs[i]\n",
        "learning_rate = learning_rates[i]\n",
        "eta_min = 1e-5\n",
        "\n",
        "print('lr:', learning_rate)\n",
        "print('SNRdB:', SNRdB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZuZDrHtO0Eo0"
      },
      "outputs": [],
      "source": [
        "# --------------- In Loop Parameters --------------\n",
        "output_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB[0]}-{SNRdB[1]}/'\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8lgyHuN0Eo0"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7zhoo24P0Eo0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib  # or use pickle if you prefer\n",
        "\n",
        "def save_scalers(scalers, save_path):\n",
        "    \"\"\"Save scalers to a file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    joblib.dump(scalers, save_path)\n",
        "\n",
        "def load_scalers(save_path):\n",
        "    \"\"\"Load scalers from a file.\"\"\"\n",
        "    return joblib.load(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.datasets.utils import *\n",
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.data_management import *\n",
        "from audioautoencoder.generate_dataset import *"
      ],
      "metadata": {
        "id": "-YEtuzpV3j2Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdO-tp40Eo0",
        "outputId": "68f1cd02-d515-4ae1-ec04-598c833287d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing scalers...\n",
            "{'input_features_spectrogram': StandardScaler(), 'target_features_spectrogram': StandardScaler()}\n",
            "Training set size: 501\n",
            "Validation set size: 126\n",
            "Training set size: 501\n",
            "Validation set size: 126\n"
          ]
        }
      ],
      "source": [
        "# Define the source and destination file paths\n",
        "if LOAD_DATA:\n",
        "  scaler_file = output_path + \"scalers.pkl\"  # Static filename since it's unique per run\n",
        "  os.makedirs(os.path.dirname(scaler_file), exist_ok=True)\n",
        "  source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "  source_path = source_folder + \"train/\"\n",
        "  destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/\"\n",
        "  save_path = source_folder + \"combined_000.h5\"\n",
        "  subset = False\n",
        "\n",
        "  if IMPORT_TRAIN_NOISY:\n",
        "    dataset_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/combined_000.h5\"\n",
        "    if not os.path.exists(destination_path):\n",
        "      combine_h5_files_features(source_path, destination_path, max_file_size_gb=max_file_size_gb)\n",
        "      #combine_h5_files_spectrograms(source_path, destination_path, max_file_size_gb=max_file_size_gb, timeout=40)\n",
        "\n",
        "    if os.path.exists(scaler_file):\n",
        "        print(\"Loading existing scalers...\")\n",
        "        scalers = load_scalers(scaler_file)\n",
        "    else:\n",
        "        print(\"Training new scalers...\")\n",
        "        #scalers = train_scalers_no_features(dataset_path, sample_size=8000)\n",
        "        scalers = train_scalers(dataset_path, sample_size=8000)\n",
        "        save_scalers(scalers, scaler_file)\n",
        "\n",
        "    print(scalers)\n",
        "\n",
        "    train_loader = ChannelDatasetLoader(\n",
        "          dataset_path=dataset_path,\n",
        "          scalers=scalers,\n",
        "          output_time_length=175,\n",
        "          channels=1,\n",
        "          snr_db=SNRdB,\n",
        "          subset=subset,\n",
        "          batch_size=batch_size,\n",
        "          num_workers=num_workers\n",
        "      )\n",
        "\n",
        "    print(f\"Training set size: {len(train_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(train_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect Data"
      ],
      "metadata": {
        "id": "GJ74jmahB2ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_DATA:\n",
        "  _, output, medatata = train_loader.train_dataset[200]\n",
        "  #input, output = train_dataset[0]\n",
        "  #print(metadata['snr_db'])\n",
        "  #print(input.shape)\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "id": "l6-sIxJ-qEDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "e57aec5e-294e-4ada-83b2-47669d7fa5d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Unable to synchronously open object (object 'input_features_cepstrum' doesn't exist)\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-169f2dde9633>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLOAD_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedatata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#input, output = train_dataset[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#print(metadata['snr_db'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#print(input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_T_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/datasets/loaders.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Load input features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0minput_spectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_features_spectrogram\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0minput_cepstrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_features_cepstrum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Define target shape (use spectrogram shape as reference)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             raise TypeError(\"Accessing a group is done with bytes or str, \"\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'input_features_cepstrum' doesn't exist)\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_DATA:\n",
        "  import matplotlib.pyplot as plt\n",
        "  import torch\n",
        "  import numpy as np\n",
        "  import torch\n",
        "\n",
        "  # Fetch a sample with SNR > 8\n",
        "  for i in range(100):\n",
        "      input_tensor, output_tensor, metadata = train_loader.train_dataset[i]\n",
        "      if metadata['snr_db'] > 8:\n",
        "          print(\"Found sample with SNR > 8:\")\n",
        "          print(\"SNR:\", metadata['snr_db'])\n",
        "          print(\"Index:\", i)\n",
        "          break  # exit loop after finding the first match\n",
        "\n",
        "\n",
        "\n",
        "  print(metadata['snr_db'])\n",
        "\n",
        "  # Convert to NumPy for plotting\n",
        "  #input_array = np.clip(input_tensor.numpy(), -1, a_max=None)\n",
        "  output_array = np.clip(output_tensor.numpy(), -1, a_max=None)\n",
        "  input_array = np.clip(input_tensor.numpy(), -1, a_max=None)\n",
        "\n",
        "  # remove negatve values\n",
        "  #input_array = torch.clamp(input_array, min=0)  # Sets all negative values to 0\n",
        "  print(np.shape(output_array))\n",
        "\n",
        "  num_channels_out = output_array.shape[0]\n",
        "  num_channels_in = input_array.shape[0]\n",
        "\n",
        "\n",
        "  # Create subplots\n",
        "  fig, axes = plt.subplots(num_channels_in + num_channels_out, 1, figsize=(15, 15))\n",
        "\n",
        "  # Plot each input channel\n",
        "  for i in range(num_channels_in):\n",
        "      input = input_array[i]\n",
        "      print(np.shape(input))\n",
        "      print('Min, Max: ', np.min(input), np.max(input))\n",
        "      im = axes[i].imshow(input, aspect='auto', cmap='magma')\n",
        "      axes[i].invert_yaxis()\n",
        "\n",
        "      axes[i].set_title(f\"Input Channel {i+1}\")\n",
        "      axes[i].axis(\"off\")\n",
        "\n",
        "      # Add colorbar\n",
        "      cbar = fig.colorbar(im, ax=axes[i], orientation=\"vertical\")\n",
        "      cbar.set_label(\"Amplitude\")\n",
        "\n",
        "    # Plot each input channel\n",
        "  for i in range(num_channels_out):\n",
        "      output = output_array[i]\n",
        "      print('Min, Max: ', np.min(output), np.max(output))\n",
        "      im = axes[num_channels_in + i].imshow(output, aspect='auto', cmap='magma')\n",
        "      axes[num_channels_in + i].invert_yaxis()\n",
        "\n",
        "      axes[num_channels_in + i].set_title(f\"Output Channel {i+1}\")\n",
        "      axes[num_channels_in + i].axis(\"off\")\n",
        "\n",
        "      # Add colorbar\n",
        "      cbar = fig.colorbar(im, ax=axes[num_channels_in + i], orientation=\"vertical\")\n",
        "      cbar.set_label(\"Amplitude\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "YO8_4lXBtXim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reverse the octave band encoding"
      ],
      "metadata": {
        "id": "5rceGlGZ1NNL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtS-e5ED0Eo0"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK_yD-3v0Eo0"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.loss import *\n",
        "from audioautoencoder.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKcwRjh60Eo0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJX1Rbee0Eo0"
      },
      "outputs": [],
      "source": [
        "if load:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "else:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "\n",
        "  #optimizer = None #torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  #scheduler = None #torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "  #scheduler_loss = False #True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.plotting import *\n",
        "from audioautoencoder.training import *"
      ],
      "metadata": {
        "id": "QlZqoKmIjeqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nJj4nyA0Eo0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clears all allocated GPU memory in PyTorch.\"\"\"\n",
        "    torch.cuda.empty_cache()  # Clears cache\n",
        "    gc.collect()  # Runs Python garbage collector\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        torch.cuda.reset_peak_memory_stats(i)  # Resets peak memory tracking\n",
        "\n",
        "clear_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.training import *"
      ],
      "metadata": {
        "id": "YwpI8xSyWJ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot example inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "ZdUysIK4fAlW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbTxS-gi0Eo0"
      },
      "outputs": [],
      "source": [
        "if train:\n",
        "  trainer = DenoisingTrainer(\n",
        "      model=model, noisy_train_loader=train_loader.train_loader, noisy_val_loader=train_loader.val_loader,\n",
        "      SNRdB=SNRdB, output_path=output_path, epochs=epochs, learning_rate=learning_rate,\n",
        "      load=load, warm_start=warm_start, train=train, verbose=False, accumulation_steps=accumulation_steps, load_path=load_path,\n",
        "      base_lr=base_lr, max_lr=max_lr, gamma=gamma, optimizer=optimizer, scheduler=scheduler, scheduler_loss=scheduler_loss,\n",
        "      max_noise=0.1, noise_epochs=5, train_diffusion=train_diffusion\n",
        "  )\n",
        "  trainer.train_or_evaluate()\n",
        "  model = trainer.get_model()\n",
        "\n",
        "  # I need a flat load model function somewhere, as now I need to define a train loader before I can load a model\n",
        "  csv_file_path = output_path + \"training_log.csv\"\n",
        "  plot_training_log(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdJxQP5_0Eo0"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}