{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owcrW1IV0Eox"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes:\n",
        "\n",
        "1. considering how much upsampling is going in in each channels for accounting for the perception of each frequency band... I could get away with downsampling the whole thing in the frequency direction by a factor of 4, 8 or even 16, reducing the sample rate post upsample.... this could worth for both the masking model and the diffusion model easily, reducing the image size from (1024, 175) to (128, 175)\n",
        "\n",
        "2. I need to edit the levels of the training data so that anything where the signal is greater than 1 (due to high noise), should be normalised to 1\n",
        "\n",
        "Next Steps:\n",
        "\n",
        "2. Compare custom res-net model with attention as masking with deeplabv3_resnet50 altered. To complete the project, compare:\n",
        "3. a) Custom simple, b) custom complex, c) deeplabv3_resnet50 d) lraspp_mobilenet_v3_large e) segformer\n",
        "4. run test and get results\n",
        "5. Write small extract on findings, and put into markdown on github."
      ],
      "metadata": {
        "id": "x_OzgxdWa-aY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uW1R-NqaTB",
        "outputId": "baccbf43-a5e4-4325-c48e-4d5d147fb453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ohND2-qaTC",
        "outputId": "5e5283ee-9930-4a43-e6d6-9baad35eda89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout dataset-generation-fix\")\n",
        "    os.system(\"git pull origin dataset-generation-fix\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin dataset-generation-fix\")\n",
        "    #os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7TDd5eSmqaTC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zyus8N0Eoy"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.models.UNetConv10mask import *\n",
        "from audioautoencoder.models.UNetConv4 import *"
      ],
      "metadata": {
        "id": "UAF0PUg2-C10"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwkxT6OP0Eoz"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReWh6Ybl0Eoz",
        "outputId": "71747ba7-5f56-4575-b755-e94584e816d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output....\n",
            "torch.Size([1, 4, 256, 175])\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1\n",
        "TEST_MODEL = True\n",
        "\n",
        "if TEST_MODEL:\n",
        "  if __name__ == \"__main__\":\n",
        "      x = torch.randn((BATCH_SIZE, 4, 1025 // 4, 175))\n",
        "      model = UNetConv4(in_channels=4, out_channels=4)\n",
        "      model.eval()\n",
        "      output = model(x)\n",
        "\n",
        "      print('output....')\n",
        "      print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "_r46u9cXkIgV",
        "outputId": "e6a1da3d-8261-4a2b-ce3a-11a2eead1350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# For example, if the input size is (batch_size=2, channels=9, height=256, width=256):\n",
        "summary(model, input_size=(2, 4, 1025 // 4, 175))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c_nBwCfNs4e",
        "outputId": "eff1069e-dee9-48c9-c817-99faf9ea8352"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "UNetConv4                                [2, 4, 256, 175]          --\n",
              "├─Sequential: 1-1                        [2, 16, 122, 82]          --\n",
              "│    └─Conv2d: 2-1                       [2, 16, 126, 86]          3,152\n",
              "│    └─BatchNorm2d: 2-2                  [2, 16, 126, 86]          32\n",
              "│    └─LeakyReLU: 2-3                    [2, 16, 126, 86]          --\n",
              "│    └─Conv2d: 2-4                       [2, 16, 122, 82]          12,560\n",
              "│    └─BatchNorm2d: 2-5                  [2, 16, 122, 82]          32\n",
              "│    └─LeakyReLU: 2-6                    [2, 16, 122, 82]          --\n",
              "├─Sequential: 1-2                        [2, 32, 58, 38]           --\n",
              "│    └─Conv2d: 2-7                       [2, 32, 60, 40]           12,832\n",
              "│    └─BatchNorm2d: 2-8                  [2, 32, 60, 40]           64\n",
              "│    └─LeakyReLU: 2-9                    [2, 32, 60, 40]           --\n",
              "│    └─Conv2d: 2-10                      [2, 32, 58, 38]           25,632\n",
              "│    └─BatchNorm2d: 2-11                 [2, 32, 58, 38]           64\n",
              "│    └─LeakyReLU: 2-12                   [2, 32, 58, 38]           --\n",
              "├─Sequential: 1-3                        [2, 64, 29, 19]           --\n",
              "│    └─Conv2d: 2-13                      [2, 64, 29, 19]           18,496\n",
              "│    └─BatchNorm2d: 2-14                 [2, 64, 29, 19]           128\n",
              "│    └─LeakyReLU: 2-15                   [2, 64, 29, 19]           --\n",
              "│    └─Conv2d: 2-16                      [2, 64, 29, 19]           36,928\n",
              "│    └─BatchNorm2d: 2-17                 [2, 64, 29, 19]           128\n",
              "│    └─LeakyReLU: 2-18                   [2, 64, 29, 19]           --\n",
              "│    └─Dropout: 2-19                     [2, 64, 29, 19]           --\n",
              "├─Sequential: 1-4                        [2, 128, 15, 10]          --\n",
              "│    └─Conv2d: 2-20                      [2, 128, 15, 10]          73,856\n",
              "│    └─BatchNorm2d: 2-21                 [2, 128, 15, 10]          256\n",
              "│    └─LeakyReLU: 2-22                   [2, 128, 15, 10]          --\n",
              "│    └─Conv2d: 2-23                      [2, 128, 15, 10]          147,584\n",
              "│    └─BatchNorm2d: 2-24                 [2, 128, 15, 10]          256\n",
              "│    └─LeakyReLU: 2-25                   [2, 128, 15, 10]          --\n",
              "│    └─Dropout: 2-26                     [2, 128, 15, 10]          --\n",
              "├─Sequential: 1-5                        [2, 256, 8, 5]            --\n",
              "│    └─Conv2d: 2-27                      [2, 256, 8, 5]            295,168\n",
              "│    └─BatchNorm2d: 2-28                 [2, 256, 8, 5]            512\n",
              "│    └─LeakyReLU: 2-29                   [2, 256, 8, 5]            --\n",
              "│    └─Conv2d: 2-30                      [2, 256, 8, 5]            590,080\n",
              "│    └─BatchNorm2d: 2-31                 [2, 256, 8, 5]            512\n",
              "│    └─LeakyReLU: 2-32                   [2, 256, 8, 5]            --\n",
              "│    └─Dropout: 2-33                     [2, 256, 8, 5]            --\n",
              "├─Sequential: 1-6                        [2, 128, 17, 11]          --\n",
              "│    └─ConvTranspose2d: 2-34             [2, 128, 17, 11]          295,040\n",
              "│    └─LeakyReLU: 2-35                   [2, 128, 17, 11]          --\n",
              "│    └─Dropout: 2-36                     [2, 128, 17, 11]          --\n",
              "├─SpatialAttention: 1-7                  [2, 128, 15, 10]          --\n",
              "│    └─Conv2d: 2-37                      [2, 1, 15, 10]            98\n",
              "│    └─Sigmoid: 2-38                     [2, 1, 15, 10]            --\n",
              "├─Sequential: 1-8                        [2, 64, 31, 21]           --\n",
              "│    └─ConvTranspose2d: 2-39             [2, 64, 31, 21]           147,520\n",
              "│    └─LeakyReLU: 2-40                   [2, 64, 31, 21]           --\n",
              "│    └─Dropout: 2-41                     [2, 64, 31, 21]           --\n",
              "├─SpatialAttention: 1-9                  [2, 64, 29, 19]           --\n",
              "│    └─Conv2d: 2-42                      [2, 1, 29, 19]            98\n",
              "│    └─Sigmoid: 2-43                     [2, 1, 29, 19]            --\n",
              "├─Sequential: 1-10                       [2, 32, 61, 41]           --\n",
              "│    └─ConvTranspose2d: 2-44             [2, 32, 61, 41]           102,432\n",
              "│    └─LeakyReLU: 2-45                   [2, 32, 61, 41]           --\n",
              "│    └─Dropout: 2-46                     [2, 32, 61, 41]           --\n",
              "├─SpatialAttention: 1-11                 [2, 32, 58, 38]           --\n",
              "│    └─Conv2d: 2-47                      [2, 1, 58, 38]            98\n",
              "│    └─Sigmoid: 2-48                     [2, 1, 58, 38]            --\n",
              "├─Sequential: 1-12                       [2, 16, 121, 81]          --\n",
              "│    └─ConvTranspose2d: 2-49             [2, 16, 121, 81]          50,192\n",
              "│    └─LeakyReLU: 2-50                   [2, 16, 121, 81]          --\n",
              "│    └─Dropout: 2-51                     [2, 16, 121, 81]          --\n",
              "├─SpatialAttention: 1-13                 [2, 16, 122, 82]          --\n",
              "│    └─Conv2d: 2-52                      [2, 1, 122, 82]           98\n",
              "│    └─Sigmoid: 2-53                     [2, 1, 122, 82]           --\n",
              "├─Conv2d: 1-14                           [2, 4, 122, 82]           1,156\n",
              "├─Sigmoid: 1-15                          [2, 4, 256, 175]          --\n",
              "==========================================================================================\n",
              "Total params: 1,815,004\n",
              "Trainable params: 1,815,004\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 2.52\n",
              "==========================================================================================\n",
              "Input size (MB): 1.43\n",
              "Forward/backward pass size (MB): 25.21\n",
              "Params size (MB): 7.26\n",
              "Estimated Total Size (MB): 33.91\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smzGryj-0Eoz"
      },
      "source": [
        "## Define Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_wGpwKW0Eo0",
        "outputId": "e7df0bd1-db92-40ca-b286-c26d90ab9dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "from audioautoencoder.plotting import *\n",
        "from audioautoencoder.datasets.utils import *\n",
        "#from audioautoencoder.models.UNetConv10mask import *\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.serialization.add_safe_globals([UNetConv4])\n",
        "model = UNetConv4(in_channels=4, out_channels=4).to(device)\n",
        "\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps1ZBM_H0Eo0",
        "outputId": "f0d8428c-917e-438c-b9f1-bc39eb33ddc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.001\n",
            "SNRdB: [-10, 10]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "train = True\n",
        "LOAD_DATA = True\n",
        "load_model = True\n",
        "\n",
        "# --------------- Main Execution parameters ---------------\n",
        "model_name = 'UNetConv4'\n",
        "train_diffusion = False\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "load_trigger = [load_model]\n",
        "#load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = 'remapped-signal-level' # sep\n",
        "\n",
        "# parameters\n",
        "learning_rates = [1e-3] # 1e-4 for re0training?, 1e-3 for training? # lowered learning rate for\n",
        "                        # when the loss explodes after the learning rate increases, it means dont increase the learning rate too much\n",
        "base_lr=1e-5\n",
        "max_lr=learning_rates[i]\n",
        "gamma=0.8\n",
        "\n",
        "# data params\n",
        "max_file_size_gb = 2#100\n",
        "IMPORT_TRAIN_NOISY = train\n",
        "batch_size = 2#256\n",
        "num_workers = 1#12\n",
        "\n",
        "# training params\n",
        "load = load_trigger[i]\n",
        "warm_start = True\n",
        "epochs = 100\n",
        "accumulation_steps = int((512*2)/batch_size)\n",
        "\n",
        "SNRdB = SNRdBs[i]\n",
        "learning_rate = learning_rates[i]\n",
        "eta_min = 1e-6\n",
        "\n",
        "print('lr:', learning_rate)\n",
        "print('SNRdB:', SNRdB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZuZDrHtO0Eo0"
      },
      "outputs": [],
      "source": [
        "# --------------- In Loop Parameters --------------\n",
        "output_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB[0]}-{SNRdB[1]}/'\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Comparison/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8lgyHuN0Eo0"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7zhoo24P0Eo0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib  # or use pickle if you prefer\n",
        "\n",
        "def save_scalers(scalers, save_path):\n",
        "    \"\"\"Save scalers to a file.\"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    joblib.dump(scalers, save_path)\n",
        "\n",
        "def load_scalers(save_path):\n",
        "    \"\"\"Load scalers from a file.\"\"\"\n",
        "    return joblib.load(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.datasets.utils import *\n",
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.data_management import *\n",
        "from audioautoencoder.generate_dataset import *"
      ],
      "metadata": {
        "id": "-YEtuzpV3j2Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdO-tp40Eo0",
        "outputId": "6c5492a7-b796-43f4-8dc4-885c3f7c4d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new file: /content/SNRdB_-10-10/train/combined_000.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing:   0%|          | 0/204 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempt 1 failed: Timeout after 20 seconds. Retrying in 3 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing:   1%|          | 2/204 [00:46<1:14:53, 22.24s/it, samples=500, size=0.668 GB]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File:/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_remapped-signal-level/SNRdB_-10-10/train/train-SNRdB_-10-10_20250408_164129.h5 skipped...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-3:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/audioautoencoder/audioautoencoder/generate_dataset.py\", line 274, in copy_operation\n",
            "    shutil.copy(src, dst)\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 431, in copy\n",
            "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 269, in copyfile\n",
            "    _fastcopy_sendfile(fsrc, fdst)\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 144, in _fastcopy_sendfile\n",
            "    sent = os.sendfile(outfd, infd, offset, blocksize)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Define the source and destination file paths\n",
        "if LOAD_DATA:\n",
        "  scaler_file = output_path + \"scalers.pkl\"  # Static filename since it's unique per run\n",
        "  os.makedirs(os.path.dirname(scaler_file), exist_ok=True)\n",
        "  source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "  source_path = source_folder + \"train/\"\n",
        "  destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/\"\n",
        "  save_path = source_folder + \"combined_000.h5\"\n",
        "  subset = False\n",
        "\n",
        "  if IMPORT_TRAIN_NOISY:\n",
        "    dataset_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/combined_000.h5\"\n",
        "    if not os.path.exists(destination_path):\n",
        "      #combine_h5_files_features(source_path, destination_path, max_file_size_gb=max_file_size_gb)\n",
        "      combine_h5_files_spectrograms(source_path, destination_path, max_file_size_gb=max_file_size_gb, timeout=40)\n",
        "\n",
        "    if os.path.exists(scaler_file):\n",
        "        print(\"Loading existing scalers...\")\n",
        "        scalers = load_scalers(scaler_file)\n",
        "    else:\n",
        "        print(\"Training new scalers...\")\n",
        "        scalers = train_scalers_no_features(dataset_path, sample_size=8000)\n",
        "        save_scalers(scalers, scaler_file)\n",
        "\n",
        "    print(scalers)\n",
        "\n",
        "    train_loader = ChannelDatasetLoader(\n",
        "          dataset_path=dataset_path,\n",
        "          scalers=scalers,\n",
        "          output_time_length=175,\n",
        "          channels=1,\n",
        "          snr_db=SNRdB,\n",
        "          subset=subset,\n",
        "          batch_size=batch_size,\n",
        "          num_workers=num_workers\n",
        "      )\n",
        "\n",
        "    print(f\"Training set size: {len(train_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(train_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect Data"
      ],
      "metadata": {
        "id": "GJ74jmahB2ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_DATA:\n",
        "  _, output, medatata = train_loader.train_dataset[200]\n",
        "  #input, output = train_dataset[0]\n",
        "  #print(metadata['snr_db'])\n",
        "  #print(input.shape)\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "id": "l6-sIxJ-qEDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_DATA:\n",
        "  import matplotlib.pyplot as plt\n",
        "  import torch\n",
        "  import numpy as np\n",
        "  import torch\n",
        "\n",
        "  # Fetch a sample\n",
        "  input_tensor, output_tensor, metadata = train_loader.train_dataset[51]\n",
        "\n",
        "  print(metadata['snr_db'])\n",
        "\n",
        "  # Convert to NumPy for plotting\n",
        "  #input_array = np.clip(input_tensor.numpy(), -1, a_max=None)\n",
        "  output_array = np.clip(output_tensor.numpy(), -1, a_max=None)\n",
        "  input_array = np.clip(input_tensor.numpy(), -1, a_max=None)\n",
        "\n",
        "  # remove negatve values\n",
        "  #input_array = torch.clamp(input_array, min=0)  # Sets all negative values to 0\n",
        "  print(np.shape(output_array))\n",
        "\n",
        "  num_channels_out = output_array.shape[0]\n",
        "  num_channels_in = input_array.shape[0]\n",
        "\n",
        "\n",
        "  # Create subplots\n",
        "  fig, axes = plt.subplots(num_channels_in + num_channels_out, 1, figsize=(15, 30))\n",
        "\n",
        "  # Plot each input channel\n",
        "  for i in range(num_channels_in):\n",
        "      input = input_array[i]\n",
        "      print(np.shape(input))\n",
        "      print('Min, Max: ', np.min(input), np.max(input))\n",
        "      im = axes[i].imshow(input, aspect='auto', cmap='magma')\n",
        "      axes[i].invert_yaxis()\n",
        "\n",
        "      axes[i].set_title(f\"Input Channel {i+1}\")\n",
        "      axes[i].axis(\"off\")\n",
        "\n",
        "      # Add colorbar\n",
        "      cbar = fig.colorbar(im, ax=axes[i], orientation=\"vertical\")\n",
        "      cbar.set_label(\"Amplitude\")\n",
        "\n",
        "    # Plot each input channel\n",
        "  for i in range(num_channels_out):\n",
        "      output = output_array[i]\n",
        "      print('Min, Max: ', np.min(output), np.max(output))\n",
        "      im = axes[num_channels_in + i].imshow(output, aspect='auto', cmap='magma')\n",
        "      axes[num_channels_in + i].invert_yaxis()\n",
        "\n",
        "      axes[num_channels_in + i].set_title(f\"Output Channel {i+1}\")\n",
        "      axes[num_channels_in + i].axis(\"off\")\n",
        "\n",
        "      # Add colorbar\n",
        "      cbar = fig.colorbar(im, ax=axes[num_channels_in + i], orientation=\"vertical\")\n",
        "      cbar.set_label(\"Amplitude\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "YO8_4lXBtXim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtS-e5ED0Eo0"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK_yD-3v0Eo0"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.loss import *\n",
        "from audioautoencoder.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKcwRjh60Eo0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJX1Rbee0Eo0"
      },
      "outputs": [],
      "source": [
        "if load:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "else:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "\n",
        "  #optimizer = None #torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  #scheduler = None #torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "  #scheduler_loss = False #True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.plotting import *\n",
        "from audioautoencoder.training import *"
      ],
      "metadata": {
        "id": "QlZqoKmIjeqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nJj4nyA0Eo0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clears all allocated GPU memory in PyTorch.\"\"\"\n",
        "    torch.cuda.empty_cache()  # Clears cache\n",
        "    gc.collect()  # Runs Python garbage collector\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        torch.cuda.reset_peak_memory_stats(i)  # Resets peak memory tracking\n",
        "\n",
        "clear_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audioautoencoder.training import *"
      ],
      "metadata": {
        "id": "YwpI8xSyWJ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot example inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "ZdUysIK4fAlW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbTxS-gi0Eo0"
      },
      "outputs": [],
      "source": [
        "if train:\n",
        "  trainer = DenoisingTrainer(\n",
        "      model=model, noisy_train_loader=train_loader.train_loader, noisy_val_loader=train_loader.val_loader,\n",
        "      SNRdB=SNRdB, output_path=output_path, epochs=epochs, learning_rate=learning_rate,\n",
        "      load=load, warm_start=warm_start, train=train, verbose=False, accumulation_steps=accumulation_steps, load_path=load_path,\n",
        "      base_lr=base_lr, max_lr=max_lr, gamma=gamma, optimizer=optimizer, scheduler=scheduler, scheduler_loss=scheduler_loss,\n",
        "      max_noise=0.1, noise_epochs=5, train_diffusion=train_diffusion\n",
        "  )\n",
        "  trainer.train_or_evaluate()\n",
        "  model = trainer.get_model()\n",
        "\n",
        "  # I need a flat load model function somewhere, as now I need to define a train loader before I can load a model\n",
        "  csv_file_path = output_path + \"training_log.csv\"\n",
        "  plot_training_log(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdJxQP5_0Eo0"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}