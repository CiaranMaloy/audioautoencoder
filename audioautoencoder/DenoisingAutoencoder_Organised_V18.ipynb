{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8SELAW0r3K8"
      },
      "source": [
        "### Idea for denoising archetecture\n",
        "0. Split datasets into existing (as primer for training and validating (0-40 dB SNR)) and new (more music samples for more background noise etc (-5-10 dB SNR))\n",
        "1. Need dedicated validation and testing sets for noisy (-5-10 dB SNR) and light-noisy (0-40 dB SNR) datsets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE8QDLOXuiE7"
      },
      "source": [
        "Environmental Sound Classification 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZVao1TXq1w"
      },
      "source": [
        "structure should be:\n",
        "\n",
        "x -> e1d -> e2d -> e3d -> bnd -> d1d -> d2d -> b3d -> y1 \\\\\n",
        "y1 * x -> e1r -> e2r -> e3r -> bnr -> d1r -> d2r -> d3r -> y2 \\\\\n",
        "\n",
        "with skip connections from e(i)d to d(i)d and d(i)r and from e(i)r ro d(i)r."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOsd6HVgBNXB",
        "outputId": "e274353b-2ae3-46e0-bf9f-050d4ee83f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ2cUzDwQQmi",
        "outputId": "6b084fa2-9b04-4501-fbf7-c82e4269657c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab...\n"
          ]
        }
      ],
      "source": [
        "# Detect Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Google Colab...\")\n",
        "    os.system(\"git clone https://github.com/CiaranMaloy/audioautoencoder\")\n",
        "    os.chdir(\"/content/audioautoencoder/\")\n",
        "    os.system(\"git pull\")\n",
        "    os.system(\"git checkout refactor\")\n",
        "    os.system(\"git pull origin refactor\")\n",
        "    os.system(\"pip install --upgrade torchmetrics\")\n",
        "else:\n",
        "    print(\"Running locally...\")\n",
        "    os.system(\"git pull origin refactor\")\n",
        "    os.system(\"pip install --upgrade torchmetrics\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "av62pZLzSUjo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/audioautoencoder')\n",
        "sys.path.append('/content/audioautoencoder/audioautoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJxpYCvxUBZZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N23OLmvVQr6V"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.data import *\n",
        "from audioautoencoder.outputs import *\n",
        "from audioautoencoder.processing import *\n",
        "from audioautoencoder.training import *\n",
        "from audioautoencoder.datasets.loaders import *\n",
        "from audioautoencoder.generate_dataset import *\n",
        "from audioautoencoder.plotting import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBX7YjnSJpLC"
      },
      "source": [
        "test get item input and output to see if i can use the log magnitude and then reverse it on the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niz7eKR1xy18"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4jLmXnwg8YL-"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.data_management import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qIB1M7xDLIFR"
      },
      "outputs": [],
      "source": [
        "GENERATE=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vHikpu86MO3s"
      },
      "outputs": [],
      "source": [
        "# Example Usage\n",
        "if GENERATE:\n",
        "  dataset_dirs = [\"/content/drive/MyDrive/Datasets/Noise/All_Noise\"]\n",
        "  output_dir = \"/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2\"\n",
        "  splits = create_datasets(dataset_dirs, output_dir)\n",
        "  print(\"Training Set:\", len(splits[\"train\"]))\n",
        "  print(\"Validation Set:\", len(splits[\"val\"]))\n",
        "  print(\"Testing Set:\", len(splits[\"test\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_C4AGBiBPsQ8"
      },
      "outputs": [],
      "source": [
        "if GENERATE:\n",
        "  save_splits_to_directories(splits, output_dir, max_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KT9U_mkQtxzx"
      },
      "outputs": [],
      "source": [
        "# generate audio files for noise and music (2s)\n",
        "if GENERATE:\n",
        "  noise_test = output_dir + \"/test\"\n",
        "  noise_train = output_dir + \"/train\"\n",
        "\n",
        "  noise_test_output = noise_test + \"-2s-44100\"\n",
        "  noise_train_output = noise_train + \"-2s-44100\"\n",
        "\n",
        "  for input_path, output_path in [(noise_test, noise_test_output), (noise_train, noise_train_output)]:\n",
        "    print(input_path, output_path)\n",
        "    generate_audio_files(input_path, output_path, t=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wf3uGYyGwS0S"
      },
      "outputs": [],
      "source": [
        "# generate audio files for noise and music (2s)\n",
        "if False:\n",
        "  music_test = \"/content/drive/MyDrive/Datasets/Music/MUSDB18--test/test\"\n",
        "  music_train = \"/content/drive/MyDrive/Datasets/Music/MUSDB18--test/train\"\n",
        "\n",
        "  music_test_output = music_test + \"-2s-44100\"\n",
        "  music_train_output = music_train + \"-2s-44100\"\n",
        "\n",
        "  for input_path, output_path in [(music_test, music_test_output), (music_train, music_train_output)]:\n",
        "    print(input_path, output_path)\n",
        "    generate_audio_files(input_path, output_path, t=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxxKjl_JOAKE"
      },
      "source": [
        "## Process files to H5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X82E9Uf6WdX_"
      },
      "outputs": [],
      "source": [
        "GENERATE_H5_FILES = False\n",
        "if GENERATE_H5_FILES:\n",
        "  processor = DatasetProcessor(\n",
        "          train_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/train-2s-44100',\n",
        "          train_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/train-2s-44100',\n",
        "          test_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/test-2s-44100',\n",
        "          test_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/test-2s-44100',\n",
        "          output_dir='/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_sep',\n",
        "          SNRdB=[-10, 10],\n",
        "          process_train=True,\n",
        "          process_test=True\n",
        "      )\n",
        "  processor.process()\n",
        "\n",
        "  processor = DatasetProcessor(\n",
        "          train_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/train-2s-44100',\n",
        "          train_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/train-2s-44100',\n",
        "          test_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/test-2s-44100',\n",
        "          test_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/test-2s-44100',\n",
        "          output_dir='/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_sep',\n",
        "          SNRdB=[0, 20],\n",
        "          process_train=True,\n",
        "          process_test=True\n",
        "      )\n",
        "  processor.process()\n",
        "\n",
        "  processor = DatasetProcessor(\n",
        "          train_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/train-2s-44100',\n",
        "          train_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/train-2s-44100',\n",
        "          test_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/test-2s-44100',\n",
        "          test_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/test-2s-44100',\n",
        "          output_dir='/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_sep',\n",
        "          SNRdB=[10, 30],\n",
        "          process_train=True,\n",
        "          process_test=True\n",
        "      )\n",
        "  processor.process()\n",
        "\n",
        "  processor = DatasetProcessor(\n",
        "          train_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/train-2s-44100',\n",
        "          train_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/train-2s-44100',\n",
        "          test_music_dir='/content/drive/MyDrive/Datasets/Music/MUSDB18/test-2s-44100',\n",
        "          test_noise_dir='/content/drive/MyDrive/Datasets/Noise/All_Noise/splits_v2/test-2s-44100',\n",
        "          output_dir='/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_mix',\n",
        "          SNRdB=[-10, 30],\n",
        "          process_train=True,\n",
        "          process_test=True,\n",
        "          mix_only=True\n",
        "      )\n",
        "  processor.process()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2m4ztn1qxC3"
      },
      "source": [
        "## Define Autoencoder structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep3iZRJC0tJi"
      },
      "source": [
        "## Improvement to UnetAutoencoder\n",
        "\n",
        "1. changed padding from explicit to on the output of the convolutional layer\n",
        "2. added batch normalisation between layers\n",
        "3. changed fro elu to leaky_relu for efficiency\n",
        "4. in the other one there is no pooling... and the skip connections are done by concatenation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ozWzWtofhJCC"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.models.UNetDenoisingAutoencoder import UNetDenoisingAutoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOXAuPserTGv"
      },
      "source": [
        "#### For v3, remove pooling layers, and add attention onto skip connections\n",
        "\n",
        "In addition, try only music and only crowd as a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zyXtMpe1PvID"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# too big without.... lets try, halfing the expansion\n",
        "# apternaitvely use max pooling instead of average pooling\n",
        "\n",
        "class UNetConv3(nn.Module):\n",
        "    # Update from UnetConv2, no pooling layers\n",
        "    def __init__(self, in_channels=2, out_channels=1):\n",
        "        super(UNetConv3, self).__init__()\n",
        "\n",
        "        a = 2\n",
        "\n",
        "        # Encoder (Downsampling)\n",
        "        enc_channels = [in_channels, 32, 64, 64, 128]\n",
        "        self.enc1 = self.conv_block(enc_channels[0], enc_channels[1], 7)\n",
        "        self.enc2 = self.conv_block(enc_channels[1], enc_channels[2], 5)\n",
        "        self.enc3 = self.conv_block(enc_channels[2], enc_channels[3], 3)\n",
        "        self.enc4 = self.conv_block(enc_channels[3], enc_channels[4], 3)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck_channels = 256\n",
        "        self.bottleneck = self.conv_block(enc_channels[4], bottleneck_channels, 3)\n",
        "\n",
        "        # Decoder (Upsampling)\n",
        "        dec_channels = [bottleneck_channels, 128, 64, 64, 32]\n",
        "        self.dec4 = self.upconv_block(dec_channels[0], dec_channels[1], 3)\n",
        "        self.dec3 = self.upconv_block(dec_channels[1] + enc_channels[4], dec_channels[2], 3)\n",
        "        self.dec2 = self.upconv_block(dec_channels[2] + enc_channels[3], dec_channels[3], 5)\n",
        "        self.dec1 = self.upconv_block(dec_channels[3] + enc_channels[2], dec_channels[4], 7)\n",
        "\n",
        "        # Final Output Layer\n",
        "        self.final = nn.Conv2d(dec_channels[4] + enc_channels[1], out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels, kernel_size, dropout=0.2):\n",
        "        \"\"\"Convolutional Block with Dropout in Deeper Layers Only\"\"\"\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        ]\n",
        "\n",
        "        # Dropout only for deeper encoder layers\n",
        "        if out_channels >= 256:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def upconv_block(self, in_channels, out_channels, kernel_size, dropout=0.2):\n",
        "        \"\"\"Upsampling Block with Dropout in First Few Decoder Layers\"\"\"\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        ]\n",
        "\n",
        "        # Dropout only for first few decoder layers\n",
        "        if in_channels >= 128:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass with skip connections\"\"\"\n",
        "        # Encoding\n",
        "        e1 = self.enc1(x)  # (batch, 64, 1028, 175)\n",
        "        e2 = self.enc2(e1) # (batch, 128, 514, 87)\n",
        "        e3 = self.enc3(e2)  # (batch, 256, 257, 43)\n",
        "        e4 = self.enc4(e3) # (batch, 512, 128, 21)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(e4)  # (batch, 1024, 64, 10)\n",
        "\n",
        "        # Decoding + Skip Connections\n",
        "        d4 = self.dec4(b)  # (batch, 512, ?, ?)\n",
        "        d4 = F.interpolate(d4, size=e4.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "\n",
        "        d3 = self.dec3(d4)  # (batch, 256, ?, ?)\n",
        "        d3 = F.interpolate(d3, size=e3.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "\n",
        "        d2 = self.dec2(d3)  # (batch, 128, ?, ?)\n",
        "        d2 = F.interpolate(d2, size=e2.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "\n",
        "        d1 = self.dec1(d2)  # (batch, 64, ?, ?)\n",
        "        d1 = F.interpolate(d1, size=e1.shape[2:], mode=\"bilinear\", align_corners=False)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "\n",
        "        # Final Convolution (output denoised spectrogram)\n",
        "        return F.interpolate(self.final(d1), size=(1025, 175), mode=\"bilinear\", align_corners=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4"
      ],
      "metadata": {
        "id": "dwpBexNA9X0Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgzwlHooHoiE",
        "outputId": "e7f76f4c-1b64-4ab8-e68b-280e2ebee9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output....\n",
            "torch.Size([4, 1, 1025, 175])\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn((BATCH_SIZE, 2, 1025, 175))\n",
        "    model = UNetConv3()\n",
        "    output = model(x)\n",
        "\n",
        "    print('output....')\n",
        "    print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB2SGHy6BEby",
        "outputId": "9675d64f-f46b-4a94-833d-674f5fd15305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running autoencoder tests...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 1.446s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 32, 1021, 171]           3,168\n",
            "       BatchNorm2d-2        [-1, 32, 1021, 171]              64\n",
            "         LeakyReLU-3        [-1, 32, 1021, 171]               0\n",
            "            Conv2d-4        [-1, 32, 1017, 167]          50,208\n",
            "       BatchNorm2d-5        [-1, 32, 1017, 167]              64\n",
            "         LeakyReLU-6        [-1, 32, 1017, 167]               0\n",
            "            Conv2d-7        [-1, 64, 1015, 165]          51,264\n",
            "       BatchNorm2d-8        [-1, 64, 1015, 165]             128\n",
            "         LeakyReLU-9        [-1, 64, 1015, 165]               0\n",
            "           Conv2d-10        [-1, 64, 1013, 163]         102,464\n",
            "      BatchNorm2d-11        [-1, 64, 1013, 163]             128\n",
            "        LeakyReLU-12        [-1, 64, 1013, 163]               0\n",
            "           Conv2d-13        [-1, 64, 1013, 163]          36,928\n",
            "      BatchNorm2d-14        [-1, 64, 1013, 163]             128\n",
            "        LeakyReLU-15        [-1, 64, 1013, 163]               0\n",
            "           Conv2d-16        [-1, 64, 1013, 163]          36,928\n",
            "      BatchNorm2d-17        [-1, 64, 1013, 163]             128\n",
            "        LeakyReLU-18        [-1, 64, 1013, 163]               0\n",
            "           Conv2d-19       [-1, 128, 1013, 163]          73,856\n",
            "      BatchNorm2d-20       [-1, 128, 1013, 163]             256\n",
            "        LeakyReLU-21       [-1, 128, 1013, 163]               0\n",
            "           Conv2d-22       [-1, 128, 1013, 163]         147,584\n",
            "      BatchNorm2d-23       [-1, 128, 1013, 163]             256\n",
            "        LeakyReLU-24       [-1, 128, 1013, 163]               0\n",
            "           Conv2d-25       [-1, 256, 1013, 163]         295,168\n",
            "      BatchNorm2d-26       [-1, 256, 1013, 163]             512\n",
            "        LeakyReLU-27       [-1, 256, 1013, 163]               0\n",
            "           Conv2d-28       [-1, 256, 1013, 163]         590,080\n",
            "      BatchNorm2d-29       [-1, 256, 1013, 163]             512\n",
            "        LeakyReLU-30       [-1, 256, 1013, 163]               0\n",
            "          Dropout-31       [-1, 256, 1013, 163]               0\n",
            "  ConvTranspose2d-32       [-1, 128, 2027, 327]         295,040\n",
            "        LeakyReLU-33       [-1, 128, 2027, 327]               0\n",
            "          Dropout-34       [-1, 128, 2027, 327]               0\n",
            "  ConvTranspose2d-35        [-1, 64, 2027, 327]         147,520\n",
            "        LeakyReLU-36        [-1, 64, 2027, 327]               0\n",
            "          Dropout-37        [-1, 64, 2027, 327]               0\n",
            "  ConvTranspose2d-38        [-1, 64, 2029, 329]         204,864\n",
            "        LeakyReLU-39        [-1, 64, 2029, 329]               0\n",
            "          Dropout-40        [-1, 64, 2029, 329]               0\n",
            "  ConvTranspose2d-41        [-1, 32, 2031, 331]         200,736\n",
            "        LeakyReLU-42        [-1, 32, 2031, 331]               0\n",
            "          Dropout-43        [-1, 32, 2031, 331]               0\n",
            "           Conv2d-44         [-1, 1, 1017, 167]             577\n",
            "================================================================\n",
            "Total params: 2,238,561\n",
            "Trainable params: 2,238,561\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.37\n",
            "Forward/backward pass size (MB): 8832.53\n",
            "Params size (MB): 8.54\n",
            "Estimated Total Size (MB): 8842.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "class TestAutoencoder(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.model = UNetConv3()\n",
        "        self.input_channels = 2\n",
        "        self.output_channels = 1\n",
        "        self.input_height = 1025\n",
        "        self.input_width = 175\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def test_model_initialization(self):\n",
        "        self.assertIsInstance(self.model, UNetConv3, \"Model initialization failed\")\n",
        "\n",
        "    def test_forward_pass(self):\n",
        "        x = torch.randn(self.batch_size, self.input_channels, self.input_height, self.input_width, device=self.device)\n",
        "        output = self.model(x)\n",
        "        self.assertEqual(\n",
        "            output.shape,\n",
        "            (self.batch_size, self.output_channels, self.input_height, self.input_width),\n",
        "            f\"Expected output shape {(self.batch_size, self.output_channels, self.input_height, self.input_width)}, but got {output.shape}\"\n",
        "        )\n",
        "\n",
        "    def test_model_summary(self):\n",
        "        try:\n",
        "            summary(self.model, input_size=(self.input_channels, self.input_height, self.input_width))\n",
        "        except Exception as e:\n",
        "            self.fail(f\"Model summary failed: {str(e)}\")\n",
        "\n",
        "# This allows running tests externally\n",
        "def suite():\n",
        "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestAutoencoder)\n",
        "    return test_suite\n",
        "\n",
        "# runner\n",
        "class TestRunner:\n",
        "    def __init__(self):\n",
        "        self.runner = unittest.TextTestRunner()\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Running autoencoder tests...\")\n",
        "        self.runner.run(suite())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    runner = TestRunner()\n",
        "    runner.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihXSxknjq_Ks"
      },
      "source": [
        "## First train as an autoencoder for music"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q-mqM2myd0F"
      },
      "source": [
        "## Download file to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hNOpNkUFSL3C"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.plotting import *\n",
        "from audioautoencoder.datasets.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzePP5Urw927",
        "outputId": "2e86e6a2-a555-4fb9-a2df-2eeaf07b2dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.001\n",
            "SNRdB: [-10, 10]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "train = True\n",
        "\n",
        "# --------------- Main Execution parameters ---------------\n",
        "model_name = 'UNetConv3'\n",
        "SNRdB_load = [-10, 10]\n",
        "SNRdBs = [[-10, 10]] # SNR random range\n",
        "load_trigger = [False]\n",
        "load_file = 'Autoencodermodel_earlystopping.pth'\n",
        "#load_file = 'Autoencodermodel_checkpoint.pth'\n",
        "\n",
        "folder = ['sep'][i] # sep\n",
        "\n",
        "# parameters\n",
        "learning_rates = [1e-3]\n",
        "\n",
        "base_lr=1e-5\n",
        "max_lr=learning_rates[i]\n",
        "gamma=0.8\n",
        "\n",
        "# data params\n",
        "max_file_size_gb = 100\n",
        "IMPORT_TRAIN_NOISY = True\n",
        "batch_size = 4\n",
        "\n",
        "# training params\n",
        "load = load_trigger[i]\n",
        "warm_start = False\n",
        "epochs = 69\n",
        "accumulation_steps = 64\n",
        "\n",
        "SNRdB = SNRdBs[i]\n",
        "learning_rate = learning_rates[i]\n",
        "eta_min = 1e-6\n",
        "\n",
        "print('lr:', learning_rate)\n",
        "print('SNRdB:', SNRdB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7DKs1xyWxBdX"
      },
      "outputs": [],
      "source": [
        "# --------------- In Loop Parameters --------------\n",
        "output_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_{model_name}_{SNRdB[0]}-{SNRdB[1]}/'\n",
        "load_path = f'/content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_{model_name}_{SNRdB_load[0]}-{SNRdB_load[1]}/{load_file}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MW2Gsna7ku_",
        "outputId": "cb3ab0be-ecc6-461c-8df1-3fc64bba2c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dataset shape: (26162, 2, 1025, 175)\n",
            "Target dataset shape: (26162, 2, 1025, 175)\n",
            "Training set size: 7325\n",
            "Validation set size: 1831\n",
            "Training set size: 7325\n",
            "Validation set size: 1831\n"
          ]
        }
      ],
      "source": [
        "# Define the source and destination file paths\n",
        "source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_{folder}/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "source_path = source_folder + \"train/\"\n",
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/\"\n",
        "save_path = source_folder + \"combined_000.h5\"\n",
        "\n",
        "if IMPORT_TRAIN_NOISY:\n",
        "  if not os.path.exists(destination_path):\n",
        "    combine_h5_files(source_path, destination_path, max_file_size_gb=max_file_size_gb)\n",
        "\n",
        "  train_loader = NoisyDatasetLoader(\n",
        "        dataset_path=f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/train/combined_000.h5\",\n",
        "        output_time_length=175,\n",
        "        channels=1,\n",
        "        snr_db=SNRdB,\n",
        "        subset=True,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "  print(f\"Training set size: {len(train_loader.train_dataset)}\")\n",
        "  print(f\"Validation set size: {len(train_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsVtpS6ksh_9"
      },
      "source": [
        "# Retrain Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MNVGzk5jK856"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.loss import *\n",
        "from audioautoencoder.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v7M1VlCI5WHr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R2BLTePNsRoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ea62e6-fb9f-4217-f1db-53d8853ef81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model, define loss function and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetConv3().to(device)\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SGiVzAgVD0Ra"
      },
      "outputs": [],
      "source": [
        "if load:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "else:\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=eta_min)\n",
        "  scheduler_loss = False\n",
        "\n",
        "  #optimizer = None #torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "  #scheduler = None #torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "  #scheduler_loss = False #True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tv3swntPn-kj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abbc1eb0-86f1-4eab-bf67-18b718746862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_UNetConv3_-10-10/Autoencodermodel_earlystopping.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/audioautoencoder/audioautoencoder/training.py:368: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(self.load_path, map_location=self.device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint keys: dict_keys(['model_state_dict', 'entire_model', 'optimizer_state_dict', 'epoch', 'total_epochs', 'loss'])\n",
            "Loss: 364.520878136158, Epoch: 8, Total epochs: 69\n",
            "Training on device: cuda\n",
            "Epoch 1, Current Learning Rate: [0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/1832 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New kl loss beta: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1832/1832 [08:01<00:00,  3.80batch/s, loss=loss: 0.1978, ref:0.1184]\n",
            "Validating: 100%|██████████| 458/458 [01:13<00:00,  6.24batch/s, loss=joint loss: 0.1369]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Epoch 1, Validation Loss: 0.1369\n",
            "Validation score improved. Saving model to /content/drive/MyDrive/Projects/ML_Projects/De-noising-autoencoder/Models_Denoising/Checkpoints_UNetConv3_-10-10/Autoencodermodel_earlystopping.pth.\n",
            "Saved to Drive...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/69], Loss: 0.1978\n",
            "--------------------------------------------------\n",
            "Epoch 2, Current Learning Rate: [0.0009755527298894294]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/1832 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New kl loss beta: 0.014492753623188406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|▉         | 180/1832 [00:56<08:40,  3.18batch/s, loss=loss: 2.2947, ref:0.1191]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5cb945a009bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/training.py\u001b[0m in \u001b[0;36mtrain_or_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;34m\"\"\"Handles the training or evaluation process based on the flag.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             train_model(\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/audioautoencoder/audioautoencoder/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, starting_epoch, epochs, verbose, checkpoint_filename, scheduler_loss, ref_min_value, accumulation_steps)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mtrue_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unscaled loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrue_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer = DenoisingTrainer(\n",
        "    model=model, noisy_train_loader=train_loader.train_loader, noisy_val_loader=train_loader.val_loader,\n",
        "    SNRdB=SNRdB, output_path=output_path, epochs=epochs, learning_rate=learning_rate,\n",
        "    load=load, warm_start=warm_start, train=train, verbose=False, accumulation_steps=accumulation_steps, load_path=load_path,\n",
        "    base_lr=base_lr, max_lr=max_lr, gamma=gamma, optimizer=optimizer, scheduler=scheduler, scheduler_loss=scheduler_loss\n",
        ")\n",
        "trainer.train_or_evaluate()\n",
        "model = trainer.get_model()\n",
        "\n",
        "# I need a flat load model function somewhere, as now I need to define a train loader before I can load a model\n",
        "csv_file_path = output_path + \"training_log.csv\"\n",
        "plot_training_log(csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VFPK5D5Xab2"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r-L1IZ-l9O7"
      },
      "source": [
        "## Testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAcVayA_pesy"
      },
      "outputs": [],
      "source": [
        "# Define the source and destination file paths\n",
        "SNRdB = [-10, 10] # SNR random range\n",
        "#filename = f\"train-SNRdB_{SNRdB}-1s-44-1khz-magnitude-freqweightmagnitude-phase.h5\"\n",
        "source_folder = f\"/content/drive/MyDrive/Datasets/Music-Noise/SNRdB_sep/SNRdB_{SNRdB[0]}-{SNRdB[1]}/\"\n",
        "source_path = source_folder + \"test/\"\n",
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
        "\n",
        "save_path = source_folder + \"combined_000.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQwjhSZJpesz"
      },
      "outputs": [],
      "source": [
        "IMPORT_TEST_NOISY = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEucu19Apesz"
      },
      "outputs": [],
      "source": [
        "max_file_size_gb = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_338U2bpesz"
      },
      "outputs": [],
      "source": [
        "destination_path = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/\"\n",
        "\n",
        "if IMPORT_TEST_NOISY:\n",
        "  if not os.path.exists(destination_path):\n",
        "    combine_h5_files(source_path, destination_path, max_file_size_gb=max_file_size_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_YpNU8IjC8V"
      },
      "source": [
        "View Pretrained Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzhAkK-I7oFr"
      },
      "outputs": [],
      "source": [
        "# checking file contents\n",
        "file = f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/combined_000.h5\"\n",
        "\n",
        "# Path to the HDF5 file\n",
        "h5_file_path = file\n",
        "n = 50\n",
        "try:\n",
        "    # Open the HDF5 file\n",
        "    with h5py.File(h5_file_path, \"r\") as h5f:\n",
        "        # Load 5 instances from the training and testing datasets\n",
        "        input_images = h5f[\"input_images\"][n:n+5]  # First 5 instances\n",
        "        target_images = h5f[\"target_images\"][n:n+5]  # First 5 instances\n",
        "        filenames = h5f[\"filenames\"][n:n+5]\n",
        "        snr_db = h5f[\"snr_db\"][n:n+5]\n",
        "\n",
        "        # Convert to NumPy arrays (if not already)\n",
        "        input_images = np.array(input_images)\n",
        "        target_images = np.array(target_images)\n",
        "        filenames = np.array(filenames)\n",
        "        snr_db = np.array(snr_db)\n",
        "\n",
        "        print(\"Loaded 5 training/testing instances:\")\n",
        "        print(\"Input dataset shape:\", input_images.shape)\n",
        "        print(\"Target dataset shape:\", target_images.shape)\n",
        "\n",
        "        print(filenames[0:3])\n",
        "        print(snr_db[0:3])\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error reading HDF5 file:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq8WWxdalRhK"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.datasets.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbFb6LzXlRhL"
      },
      "outputs": [],
      "source": [
        "if IMPORT_TEST_NOISY:\n",
        "    test_loader = NoisyDatasetLoader(\n",
        "        dataset_path=f\"/content/SNRdB_{SNRdB[0]}-{SNRdB[1]}/test/combined_000.h5\",\n",
        "        output_time_length=175,\n",
        "        channels=1,\n",
        "        snr_db=SNRdB,\n",
        "        subset=False,\n",
        "        batch_size=32,\n",
        "        metadata=True\n",
        "    )\n",
        "\n",
        "    print(f\"Training set size: {len(test_loader.train_dataset)}\")\n",
        "    print(f\"Validation set size: {len(test_loader.val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLtXGJboq-vp"
      },
      "outputs": [],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m4TfuxEJ0ti"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyyEUEWoLXYs"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.testing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTS6rjFFHy5T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from loss import *\n",
        "\n",
        "# Testing loop\n",
        "def test_model(model, test_loader, criterion):\n",
        "    evaluation = Evaluation()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0.0\n",
        "        progress_bar = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
        "        for inputs, targets, metadata in progress_bar:\n",
        "\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "          progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # evaluation\n",
        "          evaluation.evaluate(inputs, targets, outputs, metadata)\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "\n",
        "    return test_loss, evaluation.process()\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torchmetrics.audio import SignalDistortionRatio\n",
        "\n",
        "class Evaluation:\n",
        "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "        \"\"\"Initialize storage for evaluation metrics.\"\"\"\n",
        "        self.results = []\n",
        "        self.device = torch.device(device)  # Store the device\n",
        "        self.sdr = SignalDistortionRatio().to(self.device)  # Move SDR metric to the device\n",
        "\n",
        "    def evaluate(self, inputs, targets, outputs, metadata):\n",
        "        \"\"\"\n",
        "        Compute SDR and L1 loss for input vs. target and input vs. output.\n",
        "        \"\"\"\n",
        "        batch_size = inputs.shape[0]\n",
        "        chunk_length = 44100 * 2\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            filename = metadata[i][\"filename\"]\n",
        "            snr_db = metadata[i][\"snr_db\"]\n",
        "\n",
        "            input = inputs[i].detach().cpu().numpy()\n",
        "            target = targets[i].detach().cpu().numpy()\n",
        "            output = outputs[i].detach().cpu().numpy()\n",
        "\n",
        "            input_chunk = magphase_to_waveform(input[0], input[1], chunk_length)\n",
        "            output_chunk = magphase_to_waveform(output[0], input[1], chunk_length)\n",
        "            target_chunk = magphase_to_waveform(target[0], input[1], chunk_length)\n",
        "\n",
        "            # Move tensors to the correct device\n",
        "            input_chunk = torch.from_numpy(input_chunk).to(self.device).float()\n",
        "            output_chunk = torch.from_numpy(output_chunk).to(self.device).float()\n",
        "            target_chunk = torch.from_numpy(target_chunk).to(self.device).float()\n",
        "\n",
        "            input = torch.from_numpy(input).to(self.device).float()\n",
        "            output = torch.from_numpy(output).to(self.device).float()\n",
        "            target = torch.from_numpy(target).to(self.device).float()\n",
        "\n",
        "            # Compute SDR (using torchaudio)\n",
        "            sdr_invstar = self.sdr(input_chunk, target_chunk).item()\n",
        "            sdr_outvstar = self.sdr(output_chunk, target_chunk).item()\n",
        "\n",
        "            # Compute L1 loss\n",
        "            l1_invstar = F.l1_loss(input[0:1, :, :], target[0:1, :, :]).item()\n",
        "            l1_outvstar = F.l1_loss(output[0:1, :, :], target[0:1, :, :]).item()\n",
        "\n",
        "            # Store results\n",
        "            self.results.append({\n",
        "                \"instance\": len(self.results),\n",
        "                \"sdr_invstar\": sdr_invstar,\n",
        "                \"sdr_outvstar\": sdr_outvstar,\n",
        "                \"l1_invstar\": l1_invstar,\n",
        "                \"l1_outvstar\": l1_outvstar,\n",
        "                \"filename\": filename,\n",
        "                \"snr_db\": snr_db,\n",
        "            })\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"Return the stored evaluation results as a Pandas DataFrame.\"\"\"\n",
        "        return pd.DataFrame(self.results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ8jaUW4j3Pr"
      },
      "outputs": [],
      "source": [
        "criterion = nn.L1Loss()\n",
        "loss, df_eval = test_model(model, test_loader.train_loader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrOfxekHV0C3"
      },
      "outputs": [],
      "source": [
        "# Assuming `df` is your original dataframe\n",
        "df_eval[\"Improvement\"] = df_eval[\"sdr_outvstar\"] - df_eval[\"sdr_invstar\"]\n",
        "subset_columns = [\"instance\", \"sdr_invstar\", \"sdr_outvstar\", \"l1_invstar\", \"l1_outvstar\", \"filename\", \"snr_db\", \"Improvement\"]\n",
        "df_subset = df_eval[subset_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "istycCl4X5bQ"
      },
      "outputs": [],
      "source": [
        "# Create a function to map filename to a class\n",
        "def get_class_from_filename(filename, classes):\n",
        "    for keyword in classes:\n",
        "        if keyword in filename:\n",
        "            return keyword\n",
        "    return 'Unknown'  # Default if no match found\n",
        "\n",
        "df_subset[['filename_audio', 'filename_noise']] = pd.DataFrame(df_subset['filename'].tolist(), index=df_subset.index)\n",
        "df_subset['filename_audio'] = df_subset['filename_audio'].apply(lambda x: x.decode('utf-8'))\n",
        "df_subset['filename_noise'] = df_subset['filename_noise'].apply(lambda x: x.decode('utf-8'))\n",
        "\n",
        "classes = ['mixture', 'vocals', 'drums', 'guitar', 'bass', 'piano', 'electric_guitar', 'acoustic_guitar', 'synthesizer', 'strings', 'brass']\n",
        "df_subset['audio_class'] = df_subset['filename_audio'].apply(lambda x: get_class_from_filename(x, classes))\n",
        "\n",
        "classes = ['0707', 'Rain', 'Crowd', 'Water', 'Ice']\n",
        "df_subset['noise_class'] = df_subset['filename_noise'].apply(lambda x: get_class_from_filename(x, classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1scTZvFaY4lQ"
      },
      "outputs": [],
      "source": [
        "df_subset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp03uLRHVuG9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set minimal theme\n",
        "sns.set_theme(style=\"white\", font_scale=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr_Bg4xeM6zp"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = df_subset\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(10, 5))\n",
        "ax = sns.boxplot(x=\"noise_class\", y=\"Improvement\", hue=\"audio_class\", data=df)\n",
        "\n",
        "# Customize the gridlines\n",
        "for line in ax.get_ygridlines():\n",
        "    if line.get_ydata()[0] == 0:  # Check if it's the gridline at y=0\n",
        "        line.set_color('grey')  # Set color to black\n",
        "        line.set_linewidth(2)  # Set line width to make it bolder\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.savefig(output_path + f\"boxplot_all.png\")\n",
        "plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter for 'crowd' noise class\n",
        "df_crowd = df_subset[df_subset[\"noise_class\"] == \"Crowd\"].copy()\n",
        "\n",
        "# Create a grouped boxplot\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sns.boxplot(x=\"audio_class\", y=\"Improvement\", hue=\"audio_class\", data=df_crowd)\n",
        "\n",
        "# Customize the gridlines\n",
        "for line in ax.get_ygridlines():\n",
        "    if line.get_ydata()[0] == 0:  # Check if it's the gridline at y=0\n",
        "        line.set_color('grey')  # Set color to black\n",
        "        line.set_linewidth(2)  # Set line width to make it bolder\n",
        "\n",
        "# Customize plot\n",
        "plt.title(f\"Improvement by Noise Class and Audio Class: SNRdB {SNRdB[0]} to {SNRdB[1]}\")\n",
        "plt.xticks()\n",
        "#plt.legend(title=\"Audio Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.savefig(output_path + f\"boxplot_crowd.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3AQwpWnXgob"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you already have the dataframe loaded in `df`\n",
        "# df = pd.read_csv('your_data.csv')  # Uncomment if loading from CSV\n",
        "df = df_subset\n",
        "\n",
        "# You can also add visualization here if you want to dive deeper\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a more interpretable colormap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['sdr_invstar', 'sdr_outvstar', 'l1_invstar', 'l1_outvstar', 'snr_db', 'Improvement']].corr(),\n",
        "            annot=True, cmap='mako', fmt=\".2f\", vmin=-1, vmax=1, center=0)\n",
        "\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save subset dataframe\n",
        "df_subset.to_csv(output_path + f\"df_subset_SNRdB_{SNRdB[0]}-{SNRdB[1]}.csv\", index=False)"
      ],
      "metadata": {
        "id": "zVFDKMPLS42d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSQyZu_J5FnK"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "\n",
        "# Filter the dataframe for rows where Improvement is greater than 3\n",
        "filtered_df = df_eval[df_eval[\"Improvement\"] > 3]\n",
        "\n",
        "# Define the maximum number of files to write\n",
        "max_files = 5\n",
        "\n",
        "def norm(x):\n",
        "  # If x is a tensor, convert it to numpy array first\n",
        "  if isinstance(x, torch.Tensor):\n",
        "      x = x.detach().cpu().numpy()\n",
        "  return x / np.max(np.abs(x))\n",
        "\n",
        "# Loop through the filtered rows and save the chunks to WAV files, but stop at max_files\n",
        "file_count = 0\n",
        "for index, row in filtered_df.iterrows():\n",
        "    if file_count >= max_files:\n",
        "        break  # Stop if we have written the maximum number of files\n",
        "\n",
        "    input_chunk = row[\"input_chunk\"]\n",
        "    output_chunk = row[\"output_chunk\"]\n",
        "    target_chunk = row[\"target_chunk\"]\n",
        "\n",
        "    # Write to WAV files\n",
        "    input_filename = f\"/content/input_chunk_{index}.wav\"\n",
        "    output_filename = f\"/content/output_chunk_{index}.wav\"\n",
        "    target_filename = f\"/content/target_chunk_{index}.wav\"\n",
        "\n",
        "    sf.write(input_filename, norm(input_chunk), 44100)  # Assuming a sample rate of 44100 Hz\n",
        "    sf.write(output_filename, norm(output_chunk), 44100)\n",
        "    sf.write(target_filename, norm(target_chunk), 44100)\n",
        "\n",
        "    # Increment the file count\n",
        "    file_count += 1\n",
        "\n",
        "# Print how many files were written\n",
        "print(f\"Total WAV files written: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvCNTO7up5e8"
      },
      "source": [
        "# Improvements that need to be made\n",
        "\n",
        "1. Metadata h5 column, including\n",
        "- Filename\n",
        "- SNR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFd_JY_vRFJY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cooVhUuEQ5aF"
      },
      "source": [
        "## Convert some entire songs and test some metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvNP8ZZwQ2xF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "whole_files = '/content/drive/MyDrive/Datasets/Music/MUSDB18/test/'\n",
        "song_files = []\n",
        "\n",
        "# Walk through the directory tree\n",
        "for root, dirs, files in os.walk(whole_files):\n",
        "    # Filter files with '.wav' extension and 'mixture' in their name\n",
        "    for f in files:\n",
        "        if f.endswith('.wav') and 'mixture' in f:\n",
        "            full_path = os.path.join(root, f)\n",
        "            song_files.append(full_path)\n",
        "\n",
        "print(f\"\\nTotal matching files: {len(song_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hbrf6o-X0xX"
      },
      "source": [
        "Generate Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQYQ8bH4mSai"
      },
      "outputs": [],
      "source": [
        "noise_file = '/content/drive/MyDrive/Datasets/Noise/All_Noise/splits/val/Crowd Noise (1)_zkChMb.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_uxrcpp04wp"
      },
      "outputs": [],
      "source": [
        "from audioautoencoder.denoising import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWoHPPrI9dcG"
      },
      "outputs": [],
      "source": [
        "noisy_audio, sr = generate_audio_with_noise(song_files[0], noise_file, start_time=10, duration=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S5TJj7bZDnR"
      },
      "source": [
        "now the answer is to digest this waveform at 1s at a time, process those seconds, at intervals of 0.5s, window the outputs and put it back together for display on spectrograms and/or for output to .wav file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8UgbuKiWYXb"
      },
      "outputs": [],
      "source": [
        "denoiser = AudioDenoiser(model, output_path=output_path, chunk_duration=2, step_size=0.5)\n",
        "reconstructed_audio, reconstructed_input = denoiser.process_audio(noisy_audio, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN4K8F4rrwMb"
      },
      "outputs": [],
      "source": [
        "!pip install mir_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aorJVEypw2Ry"
      },
      "source": [
        "Use the SDR metric to compare signal to noise ratios of the generated output, and the standard output and demonstrate an increase in signal to noise ratio overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJjf5BGKdTEe"
      },
      "outputs": [],
      "source": [
        "average_rec = np.log(np.average(Pxx_rec, axis=1))\n",
        "average_spec = np.log(np.average(Pxx_spec, axis=1))\n",
        "\n",
        "plt.plot(average_rec)\n",
        "plt.plot(average_spec)\n",
        "plt.xscale('log')\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import mir_eval\n",
        "\n",
        "def compute_sdr(reference, estimated):\n",
        "    \"\"\"\n",
        "    Compute the Signal-to-Distortion Ratio (SDR) between reference and estimated signals.\n",
        "\n",
        "    :param reference: np.ndarray of shape (channels, samples), ground-truth clean signal\n",
        "    :param estimated: np.ndarray of shape (channels, samples), predicted separated signal\n",
        "    :return: float, SDR value in dB\n",
        "    \"\"\"\n",
        "    # Ensure inputs are 2D (stereo/multichannel) or 1D (mono)\n",
        "    reference = np.atleast_2d(reference)\n",
        "    estimated = np.atleast_2d(estimated)\n",
        "\n",
        "    # Compute SDR using mir_eval\n",
        "    sdr, _, _, _ = mir_eval.separation.bss_eval_sources(reference, estimated, compute_permutation=False)\n",
        "\n",
        "    return np.mean(sdr)  # Return average SDR across channels\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Fake reference and estimated signals (replace with actual signals)\n",
        "    ref_signal = reconstructed_audio_input  # 2 channels, 1 second at 44.1kHz\n",
        "    est_signal = reconstructed_audio  # Slightly noisy estimate\n",
        "\n",
        "    # max sdr\n",
        "    sdr_max = compute_sdr(audio, audio)\n",
        "    print(f\"SDR - : {sdr_max:.2f} dB -- Max\")\n",
        "\n",
        "    # reference sdr\n",
        "    sdr_ref = compute_sdr(audio, noisy_audio)\n",
        "    print(f\"SDR - : {sdr_ref:.2f} dB -- Reference\")\n",
        "\n",
        "    # computed srd\n",
        "    sdr_value = compute_sdr(audio, est_signal)\n",
        "    print(f\"SDR - : {sdr_value:.2f} dB -- Denoising\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}